package com.clarkparsia.protege.reasoner;

import static java.util.Collections.singleton;

import java.net.ConnectException;
import java.net.URI;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.Iterator;
import java.util.LinkedHashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.Map;
import java.util.Queue;
import java.util.Set;
import java.util.UUID;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;
import java.util.logging.Level;
import java.util.logging.Logger;

import org.mindswap.pellet.utils.DurationFormat;
import org.mindswap.pellet.utils.Timer;
import org.semanticweb.owl.inference.OWLReasonerException;
import org.semanticweb.owl.model.OWLDataFactory;
import org.semanticweb.owl.model.OWLDescription;
import org.semanticweb.owl.model.OWLException;
import org.semanticweb.owl.model.OWLOntologyChange;
import org.semanticweb.owl.vocab.OWLRDFVocabulary;

import sun.util.logging.resources.logging;

import com.clarkparsia.dig20.client.DigReasoner;
import com.clarkparsia.dig20.client.async.DigAsynchronousOperation;
import com.clarkparsia.dig20.client.async.DigAsynchronousOperationListener;
import com.clarkparsia.dig20.client.async.DigAsynchronousOperationVisitor;
import com.clarkparsia.dig20.client.async.DigOntologyChangeOperation;
import com.clarkparsia.dig20.exceptions.DigClientException;
import com.clarkparsia.dig20.exceptions.ErrorResponseException;
import com.clarkparsia.protege.change.ChangeLog;
import com.clarkparsia.protege.change.Converter;
import com.clarkparsia.protege.exceptions.ConversionException;

import edu.stanford.smi.protege.exception.ProtegeException;
import edu.stanford.smi.protege.model.Frame;
import edu.stanford.smi.protege.model.KnowledgeBase;
import edu.stanford.smi.protege.model.Project;
import edu.stanford.smi.protege.model.Slot;
import edu.stanford.smi.protege.model.framestore.FrameStoreManager;
import edu.stanford.smi.protege.server.framestore.ServerFrameStore;
import edu.stanford.smi.protege.server.job.CacheControlJob;
import edu.stanford.smi.protege.server.util.ExcludeFromSequentialTransactionsJob;
import edu.stanford.smi.protege.util.ControlFrameCalculatorCachingJob;
import edu.stanford.smi.protege.util.Log;
import edu.stanford.smi.protege.util.ProtegeJob;
import edu.stanford.smi.protegex.owl.inference.dig.exception.DIGReasonerException;
import edu.stanford.smi.protegex.owl.inference.protegeowl.ProtegeOWLReasoner;
import edu.stanford.smi.protegex.owl.inference.protegeowl.ReasonerManager;
import edu.stanford.smi.protegex.owl.inference.protegeowl.log.ReasonerLogRecord;
import edu.stanford.smi.protegex.owl.inference.protegeowl.log.ReasonerLogRecordFactory;
import edu.stanford.smi.protegex.owl.inference.protegeowl.log.ReasonerLogger;
import edu.stanford.smi.protegex.owl.inference.protegeowl.task.ReasonerTask;
import edu.stanford.smi.protegex.owl.inference.protegeowl.task.ReasonerTaskEvent;
import edu.stanford.smi.protegex.owl.inference.protegeowl.task.ReasonerTaskListener;
import edu.stanford.smi.protegex.owl.inference.protegeowl.task.protegereasoner.AbstractReasonerTask;
import edu.stanford.smi.protegex.owl.inference.reasoner.ProtegeReasoner;
import edu.stanford.smi.protegex.owl.inference.reasoner.exception.ProtegeReasonerException;
import edu.stanford.smi.protegex.owl.inference.util.ReasonerUtil;
import edu.stanford.smi.protegex.owl.model.OWLClass;
import edu.stanford.smi.protegex.owl.model.OWLDatatypeProperty;
import edu.stanford.smi.protegex.owl.model.OWLIndividual;
import edu.stanford.smi.protegex.owl.model.OWLModel;
import edu.stanford.smi.protegex.owl.model.OWLNamedClass;
import edu.stanford.smi.protegex.owl.model.OWLNames;
import edu.stanford.smi.protegex.owl.model.OWLObjectProperty;
import edu.stanford.smi.protegex.owl.model.OWLProperty;
import edu.stanford.smi.protegex.owl.model.ProtegeNames;
import edu.stanford.smi.protegex.owl.model.RDFIndividual;
import edu.stanford.smi.protegex.owl.model.RDFProperty;
import edu.stanford.smi.protegex.owl.model.RDFSClass;
import edu.stanford.smi.protegex.owl.model.framestore.LocalClassificationFrameStore;
import edu.stanford.smi.protegex.owl.model.impl.OWLUtil;

/**
 * An implementation of the ProtegeOWLReasoner interface which is backed by a Pellet-enabled DigReasoner.
 *
 * @author Michael Grove <mike@clarkparsia.com>
 * @see com.clarkparsia.protege.reasoner.CustomReasonerProjectPlugin
 */
public class CustomProtegeOWLReasoner implements ProtegeReasoner {
	
	private static class ServerReasonerSyncJob extends ProtegeJob {
		
		/**
		 * Autogenerated.
		 */
		private static final long	serialVersionUID	= 4311677679165298209L;

		public ServerReasonerSyncJob(OWLModel theModel) {
			super(theModel);
		}
		
		@Override
		public Object run() throws ProtegeException {
			((CustomProtegeOWLReasoner)ReasonerManager.getInstance().getProtegeReasoner( (OWLModel)getKnowledgeBase() )).blockPendingUpdates();
			return null;
		}
	}

    /**
	 * Starts a server side classification
	 */
	private static class ServerSideClassifyJob extends ProtegeJob {
		/**
		 * Autogenerated
		 */
		private static final long serialVersionUID = 310928003812353327L;

		public ServerSideClassifyJob(OWLModel theModel) {
			super(theModel);
		}

		@Override
		public String run() throws ProtegeException {
			CustomProtegeOWLReasoner aReasoner = (CustomProtegeOWLReasoner) ReasonerManager
					.getInstance().getProtegeReasoner((OWLModel) getKnowledgeBase());
			return aReasoner.threadedClassifyTaxonomy().toString();
		}
	}

	/**
	 * Checks the status of the classification job running on the server w/ the
	 * given UUID.
	 */
	private static class CheckStatusJob extends ProtegeJob {

		/**
		 * Autogenerated
		 */
		private static final long serialVersionUID = -4625342070436701486L;

		final private UUID mUUID;

		public CheckStatusJob(OWLModel theModel, UUID theUUID) {
			super(theModel);
			mUUID = theUUID;
		}

		@Override
		public Object run() throws ProtegeException {
			CustomProtegeOWLReasoner aReasoner = (CustomProtegeOWLReasoner) ReasonerManager
					.getInstance().getProtegeReasoner((OWLModel) getKnowledgeBase());

			return aReasoner.mStatusMap.get(mUUID);
		}
	}

    private static class DigAsyncLogger implements DigAsynchronousOperationListener,
            DigAsynchronousOperationVisitor {

        private boolean failure;
        private Throwable t;

        public void failure(DigAsynchronousOperation op) {
            this.failure = true;
            op.accept(this);
        }

        public void failure(DigAsynchronousOperation op, ErrorResponseException e) {
            this.failure = true;
            op.accept(this);
        }

        public synchronized void failure(DigAsynchronousOperation op, DigClientException t) {
            this.failure = true;
            this.t = t;
            op.accept(this);
        }

        public synchronized void success(DigAsynchronousOperation op) {
            failure = false;
            op.accept(this);
        }

        public void visit(DigOntologyChangeOperation operation) {
            if (failure) {
                if (t == null)
                    LOGGER
                            .log(Level.SEVERE,
                                    "Error affecting reasoner synchronization: asynchronous ontology change failed");
                else LOGGER
                        .log(
                                Level.SEVERE,
                                "Error affecting reasoner synchronization: asynchronous ontology change failed",
                                t);
            }
            else LOGGER.finest("Successful asynchronous ontology change");
        }
    }

    /**
     * Class that wraps the call to classifyTaxonomy as a Runnable so it can be executed in a separate thread.
     */
    private class RunnableClassify implements Runnable {
        private ReasonerStatus mStatus;

        private RunnableClassify(ReasonerStatus theStatus) {
            mStatus = theStatus;
        }

        public void run() {
            try {
                classifyTaxonomy();

                mStatus.complete();
            }
            catch (ProtegeReasonerException ex) {
                mStatus.fail(new ProtegeException(ex));
            }

            if (mCurrentStatus.equals(mStatus)) {
                mCurrentStatus = null;
            }
        }
    }

    /**
     * Runs a job on the server which tells the server to abort classification
     */
    private static class AbortJob extends ProtegeJob {
        private UUID mUUID;

        public AbortJob(OWLModel theModel, UUID theUUID) {
            super(theModel);

            mUUID = theUUID;
        }

        @Override
        public Object run() {
            CustomProtegeOWLReasoner aReasoner = ((CustomProtegeOWLReasoner)ReasonerManager.getInstance().getProtegeReasoner( (OWLModel)getKnowledgeBase() ));

            // we have a valid request to abort the current reasoner process
            if (aReasoner.mCurrentStatus != null && aReasoner.mCurrentStatus.getUUID().equals(mUUID)) {
                LOGGER.fine("Abort Request Recieved on server");

                aReasoner.mAbortRequested = true;
            }

            return null;
        }
    }

    /**
	 * Stub exception to notify that an Abort operation should/did take place
	 */
	private class AbortException extends Exception {
		/**
		 * Autogenerated
		 */
		private static final long serialVersionUID = 6205874898591909437L;
	}
	
	private static final List<OWLRDFVocabulary> BUILTIN_TERMS = Arrays.asList(
			OWLRDFVocabulary.OWL_ONTOLOGY, OWLRDFVocabulary.OWL_CLASS,
			OWLRDFVocabulary.OWL_DATA_PROPERTY,
			OWLRDFVocabulary.OWL_OBJECT_PROPERTY,
			OWLRDFVocabulary.RDF_PROPERTY, OWLRDFVocabulary.RDFS_CLASS,
			OWLRDFVocabulary.RDFS_DATATYPE);

    private Map<UUID, ReasonerStatus> mStatusMap = new LRUMap<UUID, ReasonerStatus>(10);
    private ReasonerStatus mCurrentStatus;
	
    private static final DigAsyncLogger DIG_ASYNC_LOGGER = new DigAsyncLogger();
    private static final Logger LOGGER = Log.getLogger(CustomProtegeOWLReasoner.class);
    private static final long DISPOSE_SHUTDOWN_TIMEOUT_MS = 60000;

    private boolean mAsyncUpdate;

    private Converter mConverter;

    private OWLModel mModel;

    // TODO: should we respect this flag and sometimes not synch before performing a request?
    private boolean mAutoSync = true;
    
    public static boolean SERVER_SIDE_CLASSIFY;
    public static boolean USE_LEGACY_CLASSIFICATION_CODE;
    public static boolean CACHE_CLASSIFICATION_RESULTS;

    private ExecutorService mExecutor;
    private Queue<Future<? extends DigAsynchronousOperation>> mPendingOps;
    
    private OWLNamedClass mProtegeThing;
    private OWLNamedClass mProtegeNothing;
    private RDFProperty mInfSubSlt;
    private RDFProperty mInfSupSlt;
    
    private ReasonerTaskListener mTaskListener;
    private boolean mAbortRequested = false;

	/**
	 * Stores classification results that reflect what is in the Protege structures, specifically inferredSubClassesSlot
	 * and inferredSuperclassesSlot. Having this information in memory helps us avoid database lookups to figure out if
	 * we need to reset these slots. The increased memory requirements seems to be minimal but the speedup gained is
	 * very significant. Use of this cache can be disabled by setting {@link #CACHE_CLASSIFICATION_RESULTS} to false.
	 */
    private Map<org.semanticweb.owl.model.OWLClass,ClassTreeNode> cachedClassTree;
    
    static {
		if (System.getProperty("clarkparsia.reasoner.classify.clientside") == null)
			SERVER_SIDE_CLASSIFY = true;
		else SERVER_SIDE_CLASSIFY = false;

		if (System.getProperty("clarkparsia.reasoner.classify.legacy") == null)
			USE_LEGACY_CLASSIFICATION_CODE = false;
		else USE_LEGACY_CLASSIFICATION_CODE = true;
		
		CACHE_CLASSIFICATION_RESULTS = System.getProperty("clarkparsia.reasoner.classify.cache", "true")
		                .equalsIgnoreCase("true");
	}

    /**
     * Create a new CustomProtogeOWLReasoner
     */
    public CustomProtegeOWLReasoner() {
        mConverter = new Converter(CustomReasonerProjectPlugin.getOWLDataFactory());
        cachedClassTree = new HashMap<org.semanticweb.owl.model.OWLClass,ClassTreeNode>();
    }

    /**
     * Schedules the classification to happen in another thread
     * @return the UUID of the job
     */
    private UUID threadedClassifyTaxonomy() {
        if (mCurrentStatus == null) {
            mCurrentStatus = new ReasonerStatus(ReasonerStatus.ReasonerState.Busy, "Classification Started");
            mStatusMap.put(mCurrentStatus.getUUID(), mCurrentStatus);

            mExecutor.execute(new RunnableClassify(mCurrentStatus));

            return mCurrentStatus.getUUID();
        }
        else {
            return mCurrentStatus.getUUID();
        }
    }

    /**
     * @inheritDoc
     */
    public void dispose() {
        if (mAsyncUpdate) {
            mExecutor.shutdown();
            try {
                mExecutor.awaitTermination(DISPOSE_SHUTDOWN_TIMEOUT_MS, TimeUnit.MILLISECONDS);
            }
            catch (InterruptedException e) {
                LOGGER.log(Level.WARNING,
                        "Interrupted while waiting on reasoner update queue shutdown", e);
            }
        }
    }

    private void updateReasoner(DigReasoner theReasoner) throws OWLException {
    	updateReasoner(theReasoner, false);
    }
    
    private void updateReasoner(DigReasoner theReasoner, boolean forceClassify) throws OWLException {
		LOGGER.fine("updateReasoner");

		if (mModel.getProject().isMultiUserClient()) {
			/*
			 * This will cause the client to block until the Protege server has been able to push
			 * all outstanding changes in its current queue to the explanation server
			 */
			new ServerReasonerSyncJob(mModel).execute();
		}
		else {
			ChangeLog aChangeLog = CustomReasonerProjectPlugin.getChangeLog(ServerFrameStore.getCurrentSession(), mModel);
			
			List<OWLOntologyChange> aChanges;
			synchronized( aChangeLog ) {
				aChanges = aChangeLog.asOWLOntologyChangeList();
				aChangeLog.clear();
			}

			theReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel.getProject());
			if (!aChanges.isEmpty()) {
				if (mAsyncUpdate) {
					DigOntologyChangeOperation aOp = new DigOntologyChangeOperation(
							DIG_ASYNC_LOGGER, theReasoner, aChanges);
					Future<DigOntologyChangeOperation> aFuture = mExecutor.submit(aOp, aOp);
					synchronized( mPendingOps ) {
						mPendingOps.add(aFuture);
					}
				}
				else {
					theReasoner.ontologiesChanged(aChanges);
					theReasoner.synchronize();
				}
			}
			
			if (forceClassify)
				theReasoner.classify();
		}
	}
    
	private void blockPendingUpdates() {
		if (!mAsyncUpdate) return;

		Future<? extends DigAsynchronousOperation> aPendingList[];

		synchronized( mPendingOps ) {
			aPendingList = mPendingOps.toArray(new Future[0]);
			mPendingOps.clear();
		}

		try {
			for (Future<? extends DigAsynchronousOperation> f : aPendingList) {
				f.get();
			}
		}
		catch (ExecutionException e) {
			LOGGER.log(Level.SEVERE,
					"Unexpected execution exception while blocking on pending updates", e);
			throw new RuntimeException(e);
		}
		catch (InterruptedException e) {
			LOGGER.log(Level.WARNING, "Unexpected interrupt while blocking on pending updates", e);
			Thread.currentThread().interrupt();
		}
	}

    private void synchronize(final String theMessage) {
    	if (mTaskListener == null)
    		return;
    	
        /*
		 * The DefaultProtegeDIGReasoner runs a SynchronizeReasonerTask before
		 * the ClassifyTaxonomy task. This generates a swing event (multiple
		 * actually) on the dialog which precedes the events generated during
		 * the classify task (starting below with resetHierachy). This initial
		 * event (which is run in a distinct thread) is necessary to avoid a
		 * deadlock on the awt component. The line below generates an even only
		 * for the purpose of avoiding the deadlock.
		 */
		mTaskListener.descriptionChanged( new ReasonerTaskEvent(
				new AbstractReasonerTask( this ) {

					@Override
					public String getDescription() {
						return theMessage;
					}

					public int getTaskSize() {
						throw new UnsupportedOperationException();
					}

					public void run() throws ProtegeReasonerException {
						throw new UnsupportedOperationException();
					}
				} ) );
    }

    public void classifyTaxonomy() throws ProtegeReasonerException {
        
    	synchronize("Starting classification");

    	// Disable value caching and frame calculator 
    	CacheControlJob.setCacheStatus(getKnowledgeBase(), true, true);
    	
        if (USE_LEGACY_CLASSIFICATION_CODE)
			defaultClassify();
		else {
			if (mModel.getProject().isMultiUserServer()) {
				minimizeEventClassify();
			}
			else if (mModel.getProject().isMultiUserClient() && SERVER_SIDE_CLASSIFY) {
				serverSideClassify();
			}
			else {
				efficientClassify();
			}
		}
	}
    
    private void defaultClassify() throws DIGReasonerException {

        LOGGER.fine("classifyTaxonomy");

        int aKBSize = ReasonerUtil.getInstance().getNamedClses(getKnowledgeBase()).size();

        // 1 for reset hierarchy, 1 to classify, kb size for update inconsistent, kb size for inferred hierarchy
        // kb size for the equiv classes
        DefaultReasonerTask aTask = new DefaultReasonerTask(this, 1 + 1 + aKBSize + aKBSize + aKBSize, "Classifying");

        if (mTaskListener != null)
            aTask.addTaskListener(mTaskListener);

        try {
            final Project aProject = mModel.getProject();
            final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(aProject);

            aTask.setMessage("Updating Reasoner");

            updateReasoner(aReasoner, true);

        	aTask.setDescription("Starting classification");

            aTask.setMessage("Resetting...");

            resetHierarchy(aTask);
            
            aTask.incrementProgress();
            
            aTask.setMessage("Classifying");

            aReasoner.classify();

            aTask.incrementProgress();

            aTask.setMessage("Updating Inconsistent Classes");

            updateInconsistentClasses(aTask, aReasoner);

            aTask.setMessage("Updating Inferred Hierarchy");

            updateInferredHierarchy(aTask, aReasoner);

            aTask.setMessage("Update Equivalent Classes");

            updateEquivalentClasses(aTask, aReasoner);
            
            aTask.taskCompleted();
        }
        catch (OWLReasonerException ex) {
			aTask.taskFailed();
			throw new DIGReasonerException("Classification failed!", ex);
		}
		catch (OWLException ex) {
			aTask.taskFailed();
			throw new DIGReasonerException("Classification failed!", ex);
		}
        finally {
            if (mTaskListener != null)
                aTask.removeTaskListener(mTaskListener);
        }
    }

    /**
     * Dispatches a call to the server telling it to abort the job with the given UUID
     * @param theUUID
     */
    private void abortJobOnServer(UUID theUUID) {
        LOGGER.fine("Dispatching Abort Job");

        new AbortJob(getKnowledgeBase(), theUUID).execute();
    }

    /**
     * The method to perform a classification when in client-server model
     * @throws DIGReasonerException
     */
    private void serverSideClassify() throws DIGReasonerException {
        LOGGER.fine("serverSideClassify");
        
        int taskLength = ReasonerUtil.getInstance().getNamedClses(mModel).size();
		DefaultReasonerTask aTask = new DefaultReasonerTask(this, taskLength, "Classifying On Server");
		boolean aPreviousCaching = false;
		try {
			aPreviousCaching = (Boolean)(new ControlFrameCalculatorCachingJob(mModel, false).execute());
		}
		catch (ProtegeException e) {
			Throwable cause = e.getCause();
			LOGGER.log(Level.WARNING, "Failed to disable frame calculator caching", (cause == null) ? e : cause);
		}

		try {
	        if (mTaskListener != null)
	            aTask.addTaskListener(mTaskListener);

	        Timer timer = new Timer();
	        timer.start();
	        
			ReasonerLogRecord aParentRecord;
	        aTask.setMessage("Server side job started");
	        
	        LOGGER.fine("Initiating server side classification");
			
	        aParentRecord = ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Server side job started", aTask.getParentRecord());
	        ReasonerLogger.getInstance().postLogRecord(aParentRecord);

            final ServerSideClassifyJob aJob = new ServerSideClassifyJob(mModel);
            boolean waitingOnJob = true;

            UUID aUUID = UUID.fromString( (String)aJob.execute() );
            String aLastMsg = "";
            ReasonerStatus aLastStatus = null;

            LOGGER.fine("Dispatched classification start job, now polling for status updates.");
            while (waitingOnJob) {
                try {
                    Thread.sleep(500);

                    aLastStatus = (ReasonerStatus) new CheckStatusJob(getKnowledgeBase(), aUUID).execute();

                    if (aLastStatus.isComplete() || aLastStatus.isAborted()) {
                        waitingOnJob = false;
                    }
                    else if (aLastStatus.isFailed()) {
                        throw aLastStatus.getException();
                    }
                    else {
                    	while( aTask.getProgress() < aLastStatus.getProgress()) {
                    		aTask.incrementProgress();
                    	}
                    	
                        if (aLastStatus.getMessage() != null && !aLastMsg.equals(aLastStatus.getMessage())) {
                            aTask.setMessage(aLastStatus.getMessage());
                            aLastMsg = aLastStatus.getMessage();

                            ReasonerLogRecord aRecord = ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord(aLastMsg, aParentRecord);
                            ReasonerLogger.getInstance().postLogRecord(aRecord);
                        }
                    }

                    abortCheck(aTask);
                }
                catch (InterruptedException ex) {
                    // ignore these
                }
                catch (AbortException ex) {
                    abortJobOnServer(aUUID);
                }
            }
	        
            timer.stop();
            
            String time = DurationFormat.MEDIUM.format(timer.getLast());

            LOGGER.fine("Done polling server for updates");

            if (aLastStatus != null && aLastStatus.isComplete()) {
                ReasonerLogger.getInstance().postLogRecord(ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Total time to execute server side classification (HH:MM:SS): " + time, aParentRecord));

	            LOGGER.fine("Server side classification complete: " + time);
	            
	            try {
		            final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel.getProject());	            
					int inconsistentClassesCount = aReasoner.getInconsistentClasses().size();
			        ReasonerLogger.getInstance().postLogRecord(ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Number of inconsistent classes: " + inconsistentClassesCount, aParentRecord));
				} catch (OWLReasonerException e) {
					LOGGER.log(Level.FINE, "Cannot copmute the number of inconsistent classes", e);
				}

                aTask.taskCompleted();
            }
            else if (aLastStatus.isAborted()) {
                ReasonerLogger.getInstance().postLogRecord(ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Server side classification aborted after " + time, aParentRecord));

	            LOGGER.fine("Server side classification aborted after: " + time);

                aTask.taskFailed();
                aTask.setMessage("Task Aborted");
            }
		}
		catch (ProtegeException e) {
			aTask.taskFailed();
			final Throwable t = e.getCause();
			if (t instanceof DIGReasonerException)
				throw (DIGReasonerException)t;
			else throw e;
		}
		finally {
			if (mTaskListener != null)
				aTask.removeTaskListener(mTaskListener);
		}
		
		try {
			new ControlFrameCalculatorCachingJob(mModel, aPreviousCaching).execute();
		}
		catch (ProtegeException e) {
			LOGGER.warning("Failed to enable frame calculator caching");
		}
    }

    /**
     * Check to see if an abort has been requested.
     * @param theTask the task to check for an abort, to null if there is no task to check
     * @throws AbortException thrown if there is an abort requested
     */
    private void abortCheck(ReasonerTask theTask) throws AbortException {
        if ((theTask != null && theTask.isRequestAbort()) || mAbortRequested) {
            throw new AbortException();
        }
    }

    /**
     * Cleans up the state of the world after an abort request has been recieved.  this finishes up the abort operation
     * and *MUST* be called to properly finish an abort
     */
    private void abortCleanup() {
        if (mCurrentStatus != null) {
            mCurrentStatus.aborted();
        }

        LOGGER.info("Reasoner Task aborted");
        mAbortRequested = false;

        getKnowledgeBase().rollbackTransaction();
    }
    
    private void efficientClassify() throws DIGReasonerException {
        LOGGER.fine("efficientClassify");
        
        long aStart, aEnd;
		ReasonerLogRecord aParentRecord = null;

		// It is expensive to get the collection of named classes (or the
		// size of that collection)
		DefaultReasonerTask aTask = new DefaultReasonerTask(this, 0, "Classifying");
		aTask.setProgressIndeterminate(true);

        if (mTaskListener != null) {
            aTask.addTaskListener(mTaskListener);
        }

        final OWLModel kb = getKnowledgeBase();
    	boolean eventsEnabled = kb.setGenerateEventsEnabled(false);
    	boolean undoEnabled = kb.setUndoEnabled(false);
        final Project aProject = kb.getProject();
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(aProject);
        try {
			final org.semanticweb.owl.model.OWLClass aThing = mConverter.getFactory().getOWLThing();
			final org.semanticweb.owl.model.OWLClass aNothing = mConverter.getFactory().getOWLNothing();
			final OWLNamedClass aProtegeNothing = kb.getOWLNothing();
			final OWLNamedClass aProtegeThing = kb.getOWLThingClass();

			Set<org.semanticweb.owl.model.OWLClass> visited = new HashSet<org.semanticweb.owl.model.OWLClass>();
			Map<org.semanticweb.owl.model.OWLClass, OWLNamedClass> aConvertMap = cacheNamedClasses();
			final Set<org.semanticweb.owl.model.OWLClass> aBuiltinTerms = cacheBuiltinTerms();
			
			if (aProject.isMultiUserClient()) {
				final ControlFrameCalculatorCachingJob aJob = new ControlFrameCalculatorCachingJob(
						kb, false);
				aJob.execute();
			}
			ExcludeFromSequentialTransactionsJob.setExcluded(kb, true);
			kb.beginTransaction("Classification");

			aTask.setMessage("Updating Reasoner");

			updateReasoner(aReasoner, true);

			aTask.setDescription("Classification");

            abortCheck(aTask);

            final Slot aInfSupSlt = kb.getProtegeInferredSuperclassesProperty();
			final Slot aInfSubSlt = kb.getProtegeInferredSubclassesProperty();

			aTask.setMessage("Updating Inconsistent Classes");
	        aParentRecord = ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Updating inconsistent classes",
                                                                                                     aTask.getParentRecord());
	        ReasonerLogger.getInstance().postLogRecord(aParentRecord);
	        aStart = System.currentTimeMillis();

	        Collection<OWLNamedClass> aProtegeInconsistents = new ArrayList<OWLNamedClass>();
	        {
				Set<org.semanticweb.owl.model.OWLClass> aInconsistents = aReasoner
						.getInconsistentClasses();
				if (!aInconsistents.isEmpty()) {
					for (org.semanticweb.owl.model.OWLClass aCls : aInconsistents) {
						OWLNamedClass aProtegeCls = aConvertMap.get(aCls);
						if (aProtegeCls == null) {
							LOGGER
									.warning("Failure converting inconsistent class to Protege OWLNamedClass: "
											+ aCls.getURI());
							continue;
						}

						aProtegeInconsistents.add(aProtegeCls);
						aProtegeCls
								.setClassificationStatus(OWLNames.CLASSIFICATION_STATUS_INCONSISTENT);
						// reset inferred...
						aProtegeCls.setOwnSlotValues(aInfSupSlt, Collections
								.singletonList(aProtegeNothing));

						aTask.incrementProgress();
					}
				}
				aProtegeNothing.setOwnSlotValues(aInfSubSlt, aProtegeInconsistents);
				aTask.incrementProgress();
			}
			aEnd = System.currentTimeMillis();
	        ReasonerLogger.getInstance().postLogRecord(ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Time to update inconsistent classes " + (aEnd - aStart) + "ms", aParentRecord));
	        ReasonerLogger.getInstance().postLogRecord(ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Number of inconsistent classes: " + aProtegeInconsistents.size(), aParentRecord));

			aTask.setMessage("Updating Subsumption Relationships");
	        aParentRecord = ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Updating subsumption relationships", aTask.getParentRecord());
	        ReasonerLogger.getInstance().postLogRecord(aParentRecord);

            abortCheck(aTask);

            aParentRecord = ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Updating leaves", aParentRecord);
	        ReasonerLogger.getInstance().postLogRecord(aParentRecord);
	        aStart = System.currentTimeMillis();

			Map<OWLNamedClass, List<String>> aNewSupers = new HashMap<OWLNamedClass, List<String>>();
			final Set<org.semanticweb.owl.model.OWLClass> aEmptySet = Collections.emptySet();

			aTask.setMessage("Updating Subsumption Relationships: Leaves");
			LOGGER.fine("Updating leaves");
			{
                abortCheck(aTask);
                
                List<OWLNamedClass> aProtegeLeaves = new ArrayList<OWLNamedClass>();
				Set<Set<org.semanticweb.owl.model.OWLClass>> aLeaves = aReasoner
						.getSuperClasses(aNothing);
				LOGGER.finest("Leaf fetch complete: " + aLeaves.size() + " equivalence classes");
				for (Set<org.semanticweb.owl.model.OWLClass> aLeafSet : aLeaves) {

                    abortCheck(aTask);

                    List<OWLNamedClass> aEqCls = new ArrayList<OWLNamedClass>(aLeafSet.size());
					
					for (org.semanticweb.owl.model.OWLClass aCls : aLeafSet) {
						OWLNamedClass aProtegeLeaf = aConvertMap.get(aCls);
						if (aProtegeLeaf == null) {
							LOGGER
									.warning("Failure converting class to Protege OWLNamedClass: "
											+ aCls.getURI());
							continue;
						}
						if (aProtegeLeaf.isSystem() && !aProtegeLeaf.equals(aProtegeThing)) {
							if (aLeafSet.size() > 1)
								throw new RuntimeException("System class with equivalents: "
										+ aProtegeLeaf);
							continue;
						}
						aEqCls.add(aProtegeLeaf);
						aProtegeLeaves.add(aProtegeLeaf);
						visited.add(aCls);
					}

					if (aEqCls.size() == 1) {
						OWLNamedClass aProtegeLeaf = aEqCls.get(0);
						aProtegeLeaf.setOwnSlotValues(aInfSupSlt, aEmptySet);
						aProtegeLeaf.setOwnSlotValue(aInfSubSlt, aProtegeNothing);
						
						aNewSupers.put(aProtegeLeaf, new ArrayList<String>());
					}
					else {
						for (OWLNamedClass aProtegeLeaf : aProtegeLeaves) {
							Set<OWLNamedClass> aProtegeSups = new HashSet<OWLNamedClass>(aEqCls);
							aProtegeSups.remove(aProtegeLeaf);
							aProtegeLeaf.setOwnSlotValues(aInfSupSlt, aProtegeSups);
							Set<OWLNamedClass> aProtegeSubs = new HashSet<OWLNamedClass>(
									aProtegeSups);
							aProtegeSubs.add(aProtegeNothing);
							aProtegeLeaf.setOwnSlotValues(aInfSubSlt, aProtegeSups);

							List<String> aSuperIds = new ArrayList<String>(aProtegeSups.size());
							for (Frame aFrame : aProtegeSups) {
								aSuperIds.add(aFrame.getFrameID().getName());
							}
							aNewSupers.put(aProtegeLeaf, aSuperIds);
						}
					}
				}
				aProtegeNothing.setOwnSlotValues(aInfSupSlt, aProtegeLeaves);
			}

			
			aEnd = System.currentTimeMillis();
			ReasonerLogger.getInstance().postLogRecord(ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Time to update leaves " + (aEnd - aStart) + "ms", aParentRecord));
	        aParentRecord = aParentRecord.getParent();

	        aTask.setMessage("Updating Subsumption Relationships: Internal nodes");
	        aParentRecord = ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Updating internal nodes", aParentRecord);
	        ReasonerLogger.getInstance().postLogRecord(aParentRecord);
	        aStart = System.currentTimeMillis();
	        
			LOGGER.fine("Updating non-leaf, satisfiable nodes");

            abortCheck(aTask);

            Queue<Map<? extends Collection<org.semanticweb.owl.model.OWLClass>, ? extends Collection<org.semanticweb.owl.model.OWLClass>>> aPendingTranslate = new LinkedList<Map<? extends Collection<org.semanticweb.owl.model.OWLClass>, ? extends Collection<org.semanticweb.owl.model.OWLClass>>>();

			/*
			 * Traverse the subsumption hierarchy top-down, starting with all
			 * equivalents of TOP. At each loop iteration two sets of classes
			 * are present, the supers and the subs. The sets themselves are
			 * equivalent classes. If it is the first time the subs have been
			 * seen, the subs' subs are fetched from the reasoner and pushed
			 * into the pending processing queue.
			 */
			{
				List<org.semanticweb.owl.model.OWLClass> aTops = new ArrayList<org.semanticweb.owl.model.OWLClass>(
						aReasoner.getEquivalentClasses(aThing));
				aTops.add(aThing);
				aPendingTranslate.add(Collections.singletonMap(aEmptySet, aTops));
			}

			Set<Set<org.semanticweb.owl.model.OWLClass>> aPendingDigQuery = new HashSet<Set<org.semanticweb.owl.model.OWLClass>>();
			while( !aPendingTranslate.isEmpty() ) {

                abortCheck(aTask);

                Map<? extends Collection<org.semanticweb.owl.model.OWLClass>, ? extends Collection<org.semanticweb.owl.model.OWLClass>> aCurPair = aPendingTranslate
						.remove();
				Collection<org.semanticweb.owl.model.OWLClass> aCurSups = aCurPair.keySet()
						.iterator().next();
				Collection<org.semanticweb.owl.model.OWLClass> aCurSubs = aCurPair.values()
						.iterator().next();

				List<OWLNamedClass> aProtegeSubs = new ArrayList<OWLNamedClass>(aCurSubs.size());
				List<OWLNamedClass> aProtegeSups = new ArrayList<OWLNamedClass>(aCurSups.size());

				for (org.semanticweb.owl.model.OWLClass aCls : aCurSups) {
					OWLNamedClass aProtegeCls = aConvertMap.get(aCls);
					if (aProtegeCls == null)
						throw new NullPointerException(
								"Internal error: super should be converted: " + aCls.getURI());
					aProtegeSups.add(aProtegeCls);
				}

				org.semanticweb.owl.model.OWLClass aRep = aCurSubs.iterator().next();
				boolean aNewVisit = !visited.contains(aRep);

				if (aNewVisit) {
					Set<org.semanticweb.owl.model.OWLClass> aNxtSupers = new HashSet<org.semanticweb.owl.model.OWLClass>(
							aCurSubs.size());
					for (org.semanticweb.owl.model.OWLClass aCls : aCurSubs) {
						OWLNamedClass aProtegeCls = aConvertMap.get(aCls);
						if (aProtegeCls == null) {
							LOGGER
									.warning("Failure converting class to Protege OWLNamedClass: "
											+ aCls.getURI());
							continue;
						}
						if (aProtegeCls.isSystem() && !aProtegeCls.equals(aProtegeThing)
								&& !aProtegeCls.equals(aProtegeNothing)) {
							if (aCurSubs.size() > 1)
								throw new RuntimeException("System class with equivalents: "
										+ aProtegeCls);
							continue;
						}
						
						visited.add(aCls);
						aProtegeSubs.add(aProtegeCls);
						
						aNxtSupers.add(aCls);
					}
					
					if (aProtegeSubs.size() == 1) {
						OWLNamedClass aProtegeCls = aProtegeSubs.get(0);
						aProtegeCls.setOwnSlotValues(aInfSubSlt, aEmptySet);
						aProtegeCls.setOwnSlotValues(aInfSupSlt, aProtegeSups);
						
						List<String> aSuperIds = new ArrayList<String>(aProtegeSups.size());
						for (Frame aFrame : aProtegeSups) {
							aSuperIds.add(aFrame.getFrameID().getName());
						}
						aNewSupers.put(aProtegeCls, aSuperIds);

						aTask.incrementProgress();
					}
					else {
						for (OWLNamedClass aProtegeCls : aProtegeSubs) {

							Set<OWLNamedClass> aEqs = new HashSet<OWLNamedClass>(aProtegeSubs);
							aEqs.remove(aProtegeCls);
							aProtegeCls.setOwnSlotValues(aInfSubSlt, aEqs);

							Set<OWLNamedClass> aSups = new HashSet<OWLNamedClass>(aEqs);
							aSups.addAll(aProtegeSups);
							aProtegeCls.setOwnSlotValues(aInfSupSlt, aSups);

							List<String> aSuperIds = new ArrayList<String>(aProtegeSups.size());
							for (Frame aFrame : aSups) {
								aSuperIds.add(aFrame.getFrameID().getName());
							}
							aNewSupers.put(aProtegeCls, aSuperIds);

							aTask.incrementProgress();
						}
					}
					
					for (OWLNamedClass aNamedSuper : aProtegeSups) {
						for (OWLNamedClass aNamedSub : aProtegeSubs) {
							aNamedSuper.addOwnSlotValue(aInfSubSlt, aNamedSub);
						}
					}

					/*
					 * Test if aNxtSupers is empty. If so its because conversion
					 * of all current subs failed (b/c e.g., they're system
					 * classes). If not, add the contents to the batch query
					 * from dig server coming.
					 */
					if (!aNxtSupers.isEmpty()) {
						aPendingDigQuery.add(aNxtSupers);
					}
					else {
						LOGGER.info("Ignoring subsumption relationships with super: " + aRep.getURI());
					}
				}
				else {

                    abortCheck(aTask);

                    for (org.semanticweb.owl.model.OWLClass aCls : aCurSubs) {
						OWLNamedClass aProtegeCls = aConvertMap.get(aCls);
						if (aProtegeCls == null)
							throw new NullPointerException(
									"Internal error: super should be converted: " + aCls.getURI());
						aProtegeSubs.add(aProtegeCls);
					}

                    abortCheck(aTask);

                    for (OWLNamedClass aNamedSub : aProtegeSubs) {
						List<String> aSuperIds = new ArrayList<String>(aProtegeSups.size());
						for (OWLNamedClass aNamedSup : aProtegeSups) {
							// FIXME: Bulk updates would be an improvement
							aNamedSub.addInferredSuperclass(aNamedSup);
							aSuperIds.add(aNamedSup.getFrameID().getName());
						}
						
						if (aNewSupers.containsKey(aNamedSub)) {
							aNewSupers.get(aNamedSub).addAll(aSuperIds);
						}
					}
				}

                abortCheck(aTask);

                /*
				 * Refill the pending queue by sending a batch query to the dig
				 * server
				 */
				if (aPendingTranslate.isEmpty() && !aPendingDigQuery.isEmpty()) {

					// For each equivalence class choose a representative
					Map<org.semanticweb.owl.model.OWLClass, Set<org.semanticweb.owl.model.OWLClass>> aRepElementMap = new HashMap<org.semanticweb.owl.model.OWLClass, Set<org.semanticweb.owl.model.OWLClass>>();
					for (Set<org.semanticweb.owl.model.OWLClass> aEq : aPendingDigQuery) {
						aRepElementMap.put(aEq.iterator().next(), aEq);
					}

					// Fetch subs of the representatives from the DIG server
					Map<OWLDescription, Set<Set<org.semanticweb.owl.model.OWLClass>>> aSubMap = aReasoner
							.getSubClasses(aRepElementMap.keySet());

					// Push the super/sub pairs onto the pending queue (if not
					// leaves)
					for (Map.Entry<OWLDescription, Set<Set<org.semanticweb.owl.model.OWLClass>>> aEntry : aSubMap
							.entrySet()) {
						Set<org.semanticweb.owl.model.OWLClass> aNxtSupers = aRepElementMap
								.get(aEntry.getKey());
						Set<Set<org.semanticweb.owl.model.OWLClass>> aNext = aEntry.getValue();
						int aNxtSize = aNext.size();
						for (Set<org.semanticweb.owl.model.OWLClass> aNxtSubs : aNext) {
							if (!((aNxtSize == 1) && aNxtSubs.contains(aNothing)))
								aPendingTranslate.add(Collections
										.singletonMap(aNxtSupers, aNxtSubs));
						}
					}
					
					aPendingDigQuery.clear();
				}
			}
			aConvertMap = null;

            abortCheck(aTask);

            /*
			 * Protege displays inconsistent classes based on their location in
			 * the asserted hierarchy
			 */
			for (OWLNamedClass aInconsistentCls : aProtegeInconsistents) {
				for (Object aObj : aInconsistentCls.getNamedSuperclasses()) {
					aInconsistentCls.addInferredSuperclass((RDFSClass) aObj);
				}
			}

			aEnd = System.currentTimeMillis();
	        ReasonerLogger.getInstance().postLogRecord(ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Time to update internal nodes " + (aEnd - aStart) + "ms", aParentRecord));

			aTask.setMessage("Updating Change Status");
	        aParentRecord = ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Updating change status", aTask.getParentRecord());
	        ReasonerLogger.getInstance().postLogRecord(aParentRecord);
	        aStart = System.currentTimeMillis();

            abortCheck(aTask);

            LOGGER.fine("Updating change status for named classes");
	        for (Map.Entry<OWLNamedClass, List<String>> aNewEntry : aNewSupers.entrySet()) {
				OWLNamedClass aProtegeCls = aNewEntry.getKey();
				Set<String> aNew = new HashSet<String>(aNewEntry.getValue());
				Set<String> aOld = new HashSet<String>();
				for (Frame aFrame : (Collection<OWLNamedClass>)aProtegeCls.getNamedSuperclasses()) {
					aOld.add(aFrame.getFrameID().getName());
				}
				if (aNew == null)
					throw new NullPointerException("Internal error: no previous supers: " + aProtegeCls);
				if (aOld.equals(aNew))
					aProtegeCls
							.setClassificationStatus(OWLNames.CLASSIFICATION_STATUS_CONSISTENT_AND_UNCHANGED);
				else aProtegeCls
						.setClassificationStatus(OWLNames.CLASSIFICATION_STATUS_CONSISTENT_AND_CHANGED);

				aTask.incrementProgress();
			}

	        aEnd = System.currentTimeMillis();
	        ReasonerLogger.getInstance().postLogRecord(ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Time to update change status " + (aEnd - aStart) + "ms", aParentRecord));
	        
	        String time = DurationFormat.MEDIUM.format(aEnd - aStart);
	        ReasonerLogger.getInstance().postLogRecord(ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Total time to execute client side classification (HH:MM:SS): " + time, aTask.getParentRecord()));

			aTask.taskCompleted();
			kb.commitTransaction();
		}
        catch (ErrorResponseException ex) {
            final String msg = "Classification failed on reasoner error: " + ex.getMessage();
            LOGGER.log(Level.WARNING, msg);
            aTask.taskFailed();
            kb.rollbackTransaction();
            throw new DIGReasonerException(msg);
        }
		catch (OWLReasonerException ex) {
			LOGGER.log(Level.WARNING, "Classification failed with reasoner exception", ex);
			aTask.taskFailed();
			kb.rollbackTransaction();
			throw new DIGReasonerException("Classification failed: " + ex.getMessage(), ex);
		}
		catch (OWLException ex) {
			LOGGER.log(Level.WARNING, "Classification failed with OWL exception", ex);
			aTask.taskFailed();
			kb.rollbackTransaction();
			throw new DIGReasonerException("Classification failed: " + ex.getMessage(), ex);
		}
		catch (AbortException ex) {
			aTask.taskFailed();
			aTask.setMessage("Task Aborted.");
			abortCleanup();
			ReasonerLogger.getInstance().postLogRecord(
					ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord(
							"Classification Aborted.", aParentRecord));
		}
        catch (RuntimeException ex) {
            Throwable cause = ex.getCause();
            String msg;
            if (cause != null) {
                if (cause instanceof ConnectException) {
                    msg = String.format("Failed to connect to %s : %s", aReasoner
                            .getServerURL(), cause.getMessage());
                    LOGGER.log(Level.WARNING, msg);
                }
                else {
                    msg = "Classification failed with cause: " + cause.getMessage();
                    LOGGER.log(Level.WARNING, msg, cause);
                }
            }
            else {
                msg = "Classification failed with runtime exception: " + ex.getMessage();
                LOGGER.log(Level.WARNING, msg, ex);
                cause = ex;
            }
            aTask.taskFailed();
            kb.rollbackTransaction();
            throw new DIGReasonerException(msg, ex);
        }
		finally {
			ExcludeFromSequentialTransactionsJob.setExcluded(kb, false);

			if (mTaskListener != null) aTask.removeTaskListener(mTaskListener);

			if (kb.getProject().isMultiUserClient()) {
				final ControlFrameCalculatorCachingJob aJob = new ControlFrameCalculatorCachingJob(
						kb, true);
				aJob.execute();
			}

			kb.setUndoEnabled(undoEnabled);
			kb.setGenerateEventsEnabled(eventsEnabled);
		}    	
    }
    
    /**
     * Necessary because Collections returned by Protege KB methods are ArrayLists
     */
    private static <T> boolean contentEquivalent(Set<? extends T> theSet, Collection<? extends T> theCollection) {
		return theSet.size() == theCollection.size() && theSet.containsAll(theCollection);
	}
    
    private Map<org.semanticweb.owl.model.OWLClass, OWLNamedClass> cacheNamedClasses() {
    	Map<org.semanticweb.owl.model.OWLClass, OWLNamedClass> aCache = new HashMap<org.semanticweb.owl.model.OWLClass, OWLNamedClass>();
        OWLDataFactory factory = mConverter.getFactory();
        
        // owl:Thing and owl:Nothing are valid OWL classes
        aCache.put(factory.getOWLThing(), mModel.getOWLThingClass());
        aCache.put(factory.getOWLNothing(), mModel.getOWLNothing());

        Collection aNamedClasses = ReasonerUtil.getInstance().getNamedClses(mModel);
        for (Object aObj : aNamedClasses) {
            OWLNamedClass aClass = (OWLNamedClass) aObj;
            aCache.put(factory.getOWLClass(URI.create(aClass.getName())), aClass);            
        }
        
        return aCache;
    }
    
    private Set<org.semanticweb.owl.model.OWLClass> cacheBuiltinTerms() {
    	Set<org.semanticweb.owl.model.OWLClass> aCache = new HashSet<org.semanticweb.owl.model.OWLClass>();
    	OWLDataFactory factory = mConverter.getFactory();
    	
        for (OWLRDFVocabulary builtinTerm : BUILTIN_TERMS) {
        	aCache.add(factory.getOWLClass(builtinTerm.getURI()));
		}
        
        return aCache;
    }

    private Set<OWLNamedClass> convertEqClasses(Set<org.semanticweb.owl.model.OWLClass> theClasses, Set<org.semanticweb.owl.model.OWLClass> theBuiltinTerms, Map<org.semanticweb.owl.model.OWLClass, OWLNamedClass> theCache) {
    	final Set<OWLNamedClass> aReturnSet = new HashSet<OWLNamedClass>(theClasses.size());
    	
    	for (org.semanticweb.owl.model.OWLClass aCls : theClasses) {
			if (theBuiltinTerms.contains(aCls)) {
				if (theClasses.size() > 1)
					throw new RuntimeException("System class with equivalents: " + aCls);
				continue;
	    	}
	    	else {
				OWLNamedClass aProtegeCls = theCache.get(aCls);
	
				if (aProtegeCls != null) {
					aReturnSet.add(aProtegeCls);
				}
				else {
					LOGGER.warning("Class conversion failed for " + aCls.getURI());
				}
			}
		}
    	
    	return aReturnSet;
    }
    
    private void resetSubsAndSupers(Set<OWLNamedClass> theEqCls, Set<OWLNamedClass> theStrictSupers,
			Set<OWLNamedClass> theStrictSubs) {

    	for (OWLNamedClass aCls : theEqCls) {
			Set<OWLNamedClass> aSubs;
			Set<OWLNamedClass> aSupers;

			if (theEqCls.size() > 1) {
				aSubs = new HashSet<OWLNamedClass>(theEqCls);
				aSubs.remove(aCls);
				aSubs.addAll(theStrictSubs);

				aSupers = new HashSet<OWLNamedClass>(theEqCls);
				aSupers.remove(aCls);
				aSupers.addAll(theStrictSupers);
			}
			else {
				aSubs = theStrictSubs;
				aSupers = theStrictSupers;
			}

			if (!contentEquivalent(aSubs, aCls.getInferredSubclasses()))
				aCls.setDirectOwnSlotValues(mInfSubSlt, aSubs);

			if (!contentEquivalent(aSupers, aCls.getInferredSuperclasses())) {
				aCls.setDirectOwnSlotValues(mInfSupSlt, aSupers);
			}
			
			if (!contentEquivalent(aSupers, aCls.getNamedSuperclasses())) {
				if (aCls.getClassificationStatus() != OWLNames.CLASSIFICATION_STATUS_CONSISTENT_AND_CHANGED)
					aCls
							.setClassificationStatus(OWLNames.CLASSIFICATION_STATUS_CONSISTENT_AND_CHANGED);
			}
			else if (aCls.getClassificationStatus() != OWLNames.CLASSIFICATION_STATUS_CONSISTENT_AND_UNCHANGED)
				aCls
						.setClassificationStatus(OWLNames.CLASSIFICATION_STATUS_CONSISTENT_AND_UNCHANGED);
		}

	}
    
    private static class ClassTreeNode {
		final Set<org.semanticweb.owl.model.OWLClass> mEquiv;
		final Set<Set<org.semanticweb.owl.model.OWLClass>> mSupers;
		final Set<Set<org.semanticweb.owl.model.OWLClass>> mSubs;

		ClassTreeNode(Set<org.semanticweb.owl.model.OWLClass> theEquiv,
				Set<Set<org.semanticweb.owl.model.OWLClass>> theSupers,
				Set<Set<org.semanticweb.owl.model.OWLClass>> theSubs) {
			mEquiv = theEquiv;
			mSupers = theSupers;
			mSubs = theSubs;
		}

		public Set<org.semanticweb.owl.model.OWLClass> getEquivalentClasses() {
			return mEquiv;
		}

		public Set<Set<org.semanticweb.owl.model.OWLClass>> getSuperClasses() {
			return mSupers;
		}

		public Set<Set<org.semanticweb.owl.model.OWLClass>> getSubClasses() {
			return mSubs;
		}
		
		public boolean equalsTo(ClassTreeNode that) {
			return this.mEquiv.equals(that.mEquiv) && this.mSupers.equals(that.mSupers) && this.mSubs.equals(that.mSubs);
		}
	}
    
    private static ClassTreeNode node(Set<org.semanticweb.owl.model.OWLClass> theEquiv,
				Set<Set<org.semanticweb.owl.model.OWLClass>> theSupers,
				Set<Set<org.semanticweb.owl.model.OWLClass>> theSubs) {
    	return new ClassTreeNode(theEquiv, theSupers, theSubs);
    }

    private void minimizeEventClassify() throws DIGReasonerException {
		LOGGER.fine("minimizeEventClassify");

		final org.semanticweb.owl.model.OWLClass aNothing = mConverter.getFactory().getOWLNothing();
		final org.semanticweb.owl.model.OWLClass aThing = mConverter.getFactory().getOWLThing();
		final Set<Set<org.semanticweb.owl.model.OWLClass>> aNothingSet = singleton(singleton(aNothing));

        final OWLModel kb = getKnowledgeBase();
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(kb.getProject());
		boolean undoEnabled = kb.setUndoEnabled(false);
		try {
			final Slot aInfSupSlt = kb.getProtegeInferredSuperclassesProperty();
			final Slot aInfSubSlt = kb.getProtegeInferredSubclassesProperty();

			ExcludeFromSequentialTransactionsJob.setExcluded(kb, true);
			kb.beginTransaction("Classification");

			updateReasoner(aReasoner, true);
			

			final Map<org.semanticweb.owl.model.OWLClass, OWLNamedClass> aConvertMap = cacheNamedClasses();
			final Set<org.semanticweb.owl.model.OWLClass> aBuiltinTerms = cacheBuiltinTerms();
			
			final Set<org.semanticweb.owl.model.OWLClass> aVisited = new HashSet<org.semanticweb.owl.model.OWLClass>();
			// Step 1: Identify inconsistent classes
            if (mCurrentStatus != null) {
            	mCurrentStatus.resetProgress();
                mCurrentStatus.setMessage("Updating inconsistents");
            }
            LOGGER.fine("Updating inconsistents");
            {
                // before we start this step, lets make sure there is not a pending abort
                abortCheck(null);

                Set<org.semanticweb.owl.model.OWLClass> aInconsistents = aReasoner
						.getInconsistentClasses();
				Set<OWLNamedClass> aProtegeInconsistents = convertEqClasses(aInconsistents,
						aBuiltinTerms, aConvertMap);

				for (OWLNamedClass aProtegeCls : aProtegeInconsistents) {
					if (mCurrentStatus != null) {
			            mCurrentStatus.incrementProgress();
					}
					if (aProtegeCls.getClassificationStatus() != OWLNames.CLASSIFICATION_STATUS_INCONSISTENT) {
						aProtegeCls
								.setClassificationStatus(OWLNames.CLASSIFICATION_STATUS_INCONSISTENT);
					}

					/*
					 * The set of inferred superclasses must contain the
					 * asserted supers because that is how protege roots the
					 * inconsistent class in the inferred classes tree
					 */
					Set<Object> aNewInfSupSet = new HashSet<Object>(aProtegeCls
							.getNamedSuperclasses());
					aNewInfSupSet.add(mProtegeNothing);
					if (!contentEquivalent(aNewInfSupSet, aProtegeCls.getInferredSuperclasses()))
						aProtegeCls.setOwnSlotValues(aInfSupSlt, aNewInfSupSet);
					if (!contentEquivalent(Collections.emptySet(), aProtegeCls
							.getInferredSubclasses()))
						aProtegeCls.setOwnSlotValues(aInfSubSlt, Collections.emptySet());
				}

				if (!contentEquivalent(aProtegeInconsistents, mProtegeNothing
						.getInferredSubclasses()))
					mProtegeNothing.setOwnSlotValues(aInfSubSlt, aProtegeInconsistents);

				aVisited.addAll(aInconsistents);
			}
            // Step 2: Get the leaves in a single query
            if (mCurrentStatus != null) {
                mCurrentStatus.setMessage("Updating leaves");
            }
            LOGGER.fine("Updating leaves");
            {
                // before we start this step, lets make sure there is not a pending abort
                abortCheck(null);

                Set<OWLNamedClass> aProtegeLeaves = new HashSet<OWLNamedClass>();
				Set<Set<org.semanticweb.owl.model.OWLClass>> aLeaves = aReasoner
						.getSuperClasses(aNothing);

				final Set<OWLNamedClass> aLeafStrictSubs = Collections.singleton(mProtegeNothing);

				// For each equivalence class choose a representative
				Map<org.semanticweb.owl.model.OWLClass, Set<org.semanticweb.owl.model.OWLClass>> aRepElementMap = new HashMap<org.semanticweb.owl.model.OWLClass, Set<org.semanticweb.owl.model.OWLClass>>();
				for (Set<org.semanticweb.owl.model.OWLClass> aEq : aLeaves) {
					final org.semanticweb.owl.model.OWLClass aRep = aEq.iterator().next();
					aRepElementMap.put(aRep, aEq);
				}

				LOGGER.finest("Sending superclass query to DIG server for " + aRepElementMap.size()
						+ " leaves");
				
				final long aStart = System.currentTimeMillis();
				final Map<OWLDescription, Set<Set<org.semanticweb.owl.model.OWLClass>>> aResultMap = aReasoner
						.getSuperClasses(aRepElementMap.keySet());
				LOGGER.finest("Batch query completed: " + (System.currentTimeMillis() - aStart)
						+ " ms ");

				// Set leaf nodes subs and supers
				for (Map.Entry<OWLDescription, Set<Set<org.semanticweb.owl.model.OWLClass>>> aEntry : aResultMap
						.entrySet()) {
                    // before each loop iteration, we're going to check for an abort, since this whole step takes up
                    // the majority of the server side classification time.  we dont want to go 80% of the process
                    // without ever checking for aborts, that's not very friendly.
                    abortCheck(null);
                    
                    if (mCurrentStatus != null) {
			            mCurrentStatus.incrementProgress();
					}

                    final Set<org.semanticweb.owl.model.OWLClass> aLeafSet = aRepElementMap
							.get(aEntry.getKey());
	                
	                ClassTreeNode node = node(aLeafSet,aEntry.getValue(),aNothingSet);
	                boolean updated = updateCache(node);
					
					if (updated) {				
						final Set<OWLNamedClass> aEqCls = convertEqClasses(aLeafSet, aBuiltinTerms, aConvertMap);
		
						aProtegeLeaves.addAll(aEqCls);
		
						final Set<OWLNamedClass> aLeafStrictSupers = new HashSet<OWLNamedClass>();
						for (Set<org.semanticweb.owl.model.OWLClass> aSupEqSet : aEntry.getValue()) {
							aLeafStrictSupers.addAll(convertEqClasses(aSupEqSet, aBuiltinTerms, aConvertMap));
						}						
				
						resetSubsAndSupers(aEqCls, aLeafStrictSupers, aLeafStrictSubs);
					}

					aVisited.addAll(aLeafSet);
				}

				// Set bottom's supers
				if (!contentEquivalent(aProtegeLeaves, mProtegeNothing.getInferredSuperclasses()))
					mProtegeNothing.setOwnSlotValues(aInfSupSlt, aProtegeLeaves);
			}

			Set<Set<org.semanticweb.owl.model.OWLClass>> aPendingDigQuery = new HashSet<Set<org.semanticweb.owl.model.OWLClass>>();

			// Step 3: Top nodes
            if (mCurrentStatus != null) {
                mCurrentStatus.setMessage("Updating top nodes");
            }
            LOGGER.fine("Updating top nodes");
			{
                // before we start this step, lets make sure there is not a pending abort
                abortCheck(null);

                final Set<org.semanticweb.owl.model.OWLClass> aTops = aReasoner
						.getEquivalentClasses(aThing);
				final Set<OWLNamedClass> aStrictSupers = Collections.emptySet();
				final Set<OWLNamedClass> aStrictSubs = new HashSet<OWLNamedClass>();
				final Set<OWLNamedClass> aEqCls = convertEqClasses(aTops, aBuiltinTerms, aConvertMap);
				aEqCls.add(mProtegeThing);

				for (Set<org.semanticweb.owl.model.OWLClass> aSubSet : aReasoner
						.getSubClasses(aThing)) {
					if (mCurrentStatus != null) {
			            mCurrentStatus.incrementProgress();
					}
					
					final Set<OWLNamedClass> aProtegeSubs = convertEqClasses(aSubSet, aBuiltinTerms, aConvertMap);
					aStrictSubs.addAll(aProtegeSubs);
					aPendingDigQuery.add(aSubSet);
				}

				resetSubsAndSupers(aEqCls, aStrictSupers, aStrictSubs);

				aVisited.addAll(aTops);
			}

			/*
			 * Step 4: Traverse the subsumption hierarchy top-down, starting
			 * with all equivalents of TOP. At each loop iteration two sets of
			 * classes are present, the supers and the subs. The sets themselves
			 * are equivalent classes. If it is the first time the subs have
			 * been seen, the subs' subs are fetched from the reasoner and
			 * pushed into the pending processing queue.
			 */

			Queue<ClassTreeNode> aPendingTranslate = new LinkedList<ClassTreeNode>();
            if (mCurrentStatus != null) {
                mCurrentStatus.setMessage("Updating internal, satisfiable nodes");
            }
            LOGGER.fine("Updating internal, satisfiable nodes");
			do {
                // before we start this step, lets make sure there is not a pending abort
                abortCheck(null);
                

                /*
				 * 1) Refill the pending translate queue by sending a batch
				 * query to the dig server
				 */

				// For each equivalence class choose a representative, dropping
				// classes we've visited before
				Map<org.semanticweb.owl.model.OWLClass, Set<org.semanticweb.owl.model.OWLClass>> aRepElementMap = new HashMap<org.semanticweb.owl.model.OWLClass, Set<org.semanticweb.owl.model.OWLClass>>();
				for (Set<org.semanticweb.owl.model.OWLClass> aEq : aPendingDigQuery) {
					final org.semanticweb.owl.model.OWLClass aRep = aEq.iterator().next();
					if (!aVisited.contains(aRep)) aRepElementMap.put(aRep, aEq);
				}

				// Fetch subs and supers of the representatives from the DIG
				// server
				LOGGER.finest("Sending sub and superclass query to DIG server for "
						+ aRepElementMap.size() + " classes");
				final Map<OWLDescription, Set<Set<org.semanticweb.owl.model.OWLClass>>[]> aResultMap = aReasoner
						.getSubSuperClasses(aRepElementMap.keySet());

				// Push ClassTreeNodes onto the pending queue
				for (Map.Entry<OWLDescription, Set<Set<org.semanticweb.owl.model.OWLClass>>[]> aEntry : aResultMap
						.entrySet()) {
					aPendingTranslate.add(node(aRepElementMap.get(aEntry.getKey()), aEntry
							.getValue()[DigReasoner.SUPERS_INDEX],
							aEntry.getValue()[DigReasoner.SUBS_INDEX]));
				}

				aPendingDigQuery.clear();

				/*
				 * 2) Process the results of all queries made, possibly queuing
				 * new queries
				 */

				while( !aPendingTranslate.isEmpty() ) {
					if (mCurrentStatus != null) {
			            mCurrentStatus.incrementProgress();
					}
					
					final ClassTreeNode aNode = aPendingTranslate.remove();

					final Set<OWLNamedClass> aEqCls = convertEqClasses(
							aNode.getEquivalentClasses(), aBuiltinTerms, aConvertMap);
					final Set<OWLNamedClass> aStrictSupers = new HashSet<OWLNamedClass>();
					final Set<OWLNamedClass> aStrictSubs = new HashSet<OWLNamedClass>();

					for (Set<org.semanticweb.owl.model.OWLClass> aSupEqCls : aNode
							.getSuperClasses()) {
						aStrictSupers.addAll(convertEqClasses(aSupEqCls, aBuiltinTerms, aConvertMap));
					}

					for (Set<org.semanticweb.owl.model.OWLClass> aSubEqCls : aNode.getSubClasses()) {
						aStrictSubs.addAll(convertEqClasses(aSubEqCls, aBuiltinTerms, aConvertMap));
					}


	                boolean updated = updateCache(aNode);					
					if (updated)
						resetSubsAndSupers(aEqCls, aStrictSupers, aStrictSubs);

					aVisited.addAll(aNode.getEquivalentClasses());
					aPendingDigQuery.addAll(aNode.getSubClasses());
				}

			} while( !aPendingDigQuery.isEmpty() );

            if (mCurrentStatus != null) {
                mCurrentStatus.setMessage("Committing transaction");
            }
            LOGGER.fine("Classification complete, committing");

            kb.commitTransaction();
            
            if (mCurrentStatus != null) {
                mCurrentStatus.setMessage("Complete");
            }
            
            if (mCurrentStatus != null) {
	            mCurrentStatus.resetProgress();
			}
            LOGGER.fine("Commit complete");
		}
        catch (ErrorResponseException ex) {
            final String msg = "Classification failed on reasoner error: " + ex.getMessage();
            LOGGER.log(Level.WARNING, msg);
            kb.rollbackTransaction();
            throw new DIGReasonerException(msg);
        }
		catch (OWLReasonerException ex) {
			LOGGER.log(Level.WARNING, "Classification failed with reasoner exception", ex);
			kb.rollbackTransaction();
			throw new DIGReasonerException("Classification failed!", ex);
		}
		catch (OWLException ex) {
			LOGGER.log(Level.WARNING, "Classification failed with OWLAPI exception", ex);
			kb.rollbackTransaction();
			throw new DIGReasonerException("Classification failed!", ex);
		}
		catch (AbortException ex) {
			abortCleanup();
		}
		catch (RuntimeException ex) {
			LOGGER.log(Level.WARNING, "Classification failed with runtime exception", ex);
			kb.rollbackTransaction();
			throw new DIGReasonerException("Classification failed!", ex);
		}
		finally {
			ExcludeFromSequentialTransactionsJob.setExcluded(kb, false);
			kb.setUndoEnabled(undoEnabled);
		}
	}

	/**
	 * Updates the cached classification results for the classes in this node and return <code>true</code> if the
	 * results in the cache are different. Returning <code>false</code> means the informaiton in the cache was same and
	 * no updates to Protege structures are needed. If caching is disabled, this function will always return
	 * <code>true</code> to make sure Protege structures will be updated.
	 */
    private boolean updateCache(ClassTreeNode node) {
    	if (!CACHE_CLASSIFICATION_RESULTS)
    		return true;
    	
    	boolean updated = false;
		for (org.semanticweb.owl.model.OWLClass aClass : node.getEquivalentClasses()) {
			ClassTreeNode existing = cachedClassTree.get(aClass);
			if (existing == null || !existing.equalsTo(node)) {
				if( existing!=null ) {
					if (LOGGER.isLoggable(Level.FINER))
						LOGGER.finer("Updating cache: " + existing+ "\n     New value: " + node );
				}
				cachedClassTree.put(aClass, node);
				updated = true;
			}
		}
		
		return updated;
    }

	public void computeEquivalentConcepts() throws ProtegeReasonerException {
        int aKBSize = ReasonerUtil.getInstance().getNamedClses(getKnowledgeBase()).size();
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel
                .getProject());

        // 1 to classify, kb size for the compute equiv classes
        DefaultReasonerTask aTask = new DefaultReasonerTask(this, 1 + aKBSize, "Computing equivalent classes");

        if (mTaskListener != null)
            aTask.addTaskListener(mTaskListener);

        try {
            aTask.setMessage("Updating Reasoner");

            updateReasoner(aReasoner);

            aTask.setMessage("Classifying");

            aReasoner.classify();

            aTask.incrementProgress();

            aTask.setMessage("Update Equivalent Classes");

            updateEquivalentClasses(aTask, aReasoner);

            aTask.taskCompleted();
        }
        catch (OWLReasonerException ex) {
            aTask.taskFailed();

            throw new DIGReasonerException("compute equivalents failed!", ex);
        }
        catch( OWLException ex ) {
            aTask.taskFailed();

            throw new DIGReasonerException("compute equivalents failed!", ex);
		}
        finally {
            if (mTaskListener != null)
                aTask.removeTaskListener(mTaskListener);
        }
    }

	public void computeInconsistentConcepts() throws DIGReasonerException {
        int aKBSize = ReasonerUtil.getInstance().getNamedClses(getKnowledgeBase()).size();
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel
                .getProject());

        // 1 to classify, kb size for the compute inconsistent classes
        DefaultReasonerTask aTask = new DefaultReasonerTask(this, 1 + aKBSize, "Computing inconsistent classes");

        if (mTaskListener != null)
            aTask.addTaskListener(mTaskListener);

        try {
            aTask.setMessage("Updating Reasoner");

            updateReasoner(aReasoner);

            aTask.setMessage("Classifying");

            aReasoner.classify();

            aTask.incrementProgress();

            aTask.setMessage("Updating inconsistent classes");            

            updateInconsistentClasses(aTask, aReasoner);

            aTask.taskCompleted();
        }
        catch (OWLReasonerException ex) {
            aTask.taskFailed();

            throw new DIGReasonerException("compute inconsistent concepts failed!", ex);
        }
        catch( OWLException ex ) {
            aTask.taskFailed();

            throw new DIGReasonerException("compute inconsistent concepts failed!", ex);
		}
        finally {
            if (mTaskListener != null)
                aTask.removeTaskListener(mTaskListener);
        }
    }

	public void computeInferredHierarchy() throws DIGReasonerException {
        int aKBSize = ReasonerUtil.getInstance().getNamedClses(getKnowledgeBase()).size();
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel
                .getProject());

        // 1 to classify, kb size for the update inf. hierarchy
        DefaultReasonerTask aTask = new DefaultReasonerTask(this, 1 + aKBSize, "Computing inferred hierarchy types");

        if (mTaskListener != null)
            aTask.addTaskListener(mTaskListener);

        try {
            aTask.setMessage("Updating Reasoner");

            updateReasoner(aReasoner);

            aTask.setMessage("Classifying");

            aReasoner.classify();

            aTask.incrementProgress();

            aTask.setMessage("Updating inferred hierarchy");

            updateInferredHierarchy(aTask, aReasoner);

            aTask.taskCompleted();
        }
        catch (OWLReasonerException ex) {
            aTask.taskFailed();

            throw new DIGReasonerException("computer inferred hierarchy failed!", ex);
        }
        catch( OWLException ex ) {
            aTask.taskFailed();

            throw new DIGReasonerException("compute inferred hierarchy failed!", ex);
		}
        finally {
            if (mTaskListener != null)
                aTask.removeTaskListener(mTaskListener);
        }
    }

	public void computeInferredIndividualTypes() throws DIGReasonerException {
        int aSize = ReasonerUtil.getInstance().getIndividuals(getKnowledgeBase()).size();
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel
                .getProject());

        // 1 to realize, # of ind's for the update individual types
        DefaultReasonerTask aTask = new DefaultReasonerTask(this, 1 + aSize, "Computing inferred individual types");

        if (mTaskListener != null)
            aTask.addTaskListener(mTaskListener);

        try {
            aTask.setMessage("Updating Reasoner");

            updateReasoner(aReasoner);

            aTask.setMessage("Realizing");

            aReasoner.realise();

            aTask.incrementProgress();

            aTask.setMessage("Updating inferred types");

            updateInferredTypes(aTask, aReasoner);

            aTask.taskCompleted();
        }
        catch (OWLReasonerException ex) {
            aTask.taskFailed();

            throw new DIGReasonerException("computer inferred individual types failed!", ex);
        }
        catch( OWLException ex ) {
            aTask.taskFailed();

            throw new DIGReasonerException("compute inferred individual types failed!", ex);
		}
        finally {
            if (mTaskListener != null)
                aTask.removeTaskListener(mTaskListener);
        }
    }

	public void forceReasonerReSynchronization() {
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel
                .getProject());
        try {
            updateReasoner(aReasoner);
        }
        catch (OWLException ex) {
            LOGGER
                    .log(
                            Level.WARNING,
                            "Error with forced reasoner synchronization.  Wrapping and rethrowing exception",
                            ex);
            throw new RuntimeException("OWLException caught", ex);
        }
    }

	public Collection<OWLClass> getAncestorClasses(OWLClass theClass) throws DIGReasonerException {
        DefaultReasonerTask aTask = new DefaultReasonerTask(this, 1, "Get ancestor classes of " + theClass);
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel.getProject());

        if (mTaskListener != null)
            aTask.addTaskListener(mTaskListener);

        try {
            aTask.setMessage("Updating Reasoner");

            updateReasoner(aReasoner);

            aTask.setMessage("Getting ancestor Classes of " + theClass);

            Set<Set<org.semanticweb.owl.model.OWLClass>> aAncestors = aReasoner.getAncestorClasses(mConverter.convertClass(theClass));

            Set<OWLClass> aList = new HashSet<OWLClass>();

            for (Set<org.semanticweb.owl.model.OWLClass> aSet : aAncestors) {
                for (org.semanticweb.owl.model.OWLClass aClass : aSet) {
                    aList.add(mConverter.toProtegeClass(aClass, getKnowledgeBase()));
                }
            }

            aTask.incrementProgress();

            aTask.taskCompleted();

            return aList;
        }
        catch (OWLReasonerException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Reasoner error", e);
		}
		catch (ConversionException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Protege to OWLAPI conversion error", e);
		}
		catch (OWLException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("OWLAPI error", e);
		}
		finally {
			if (mTaskListener != null) aTask.removeTaskListener(mTaskListener);
		}
    }

	public Collection<OWLClass> getDescendantClasses(OWLClass theClass) throws DIGReasonerException {
        DefaultReasonerTask aTask = new DefaultReasonerTask(this, 1, "Get descendant classes of " + theClass);
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel.getProject());

        if (mTaskListener != null)
            aTask.addTaskListener(mTaskListener);

        try {
            aTask.setMessage("Updating Reasoner");

            updateReasoner(aReasoner);

            aTask.setMessage("Getting descendant Classes of " + theClass);

            Set<Set<org.semanticweb.owl.model.OWLClass>> aDescendants = aReasoner.getDescendantClasses(mConverter.convertClass(theClass));

            Set<OWLClass> aList = new HashSet<OWLClass>();

            for (Set<org.semanticweb.owl.model.OWLClass> aSet : aDescendants) {
                for (org.semanticweb.owl.model.OWLClass aClass : aSet) {
                    aList.add(mConverter.toProtegeClass(aClass, getKnowledgeBase()));
                }
            }

            aTask.incrementProgress();

            aTask.taskCompleted();

            return aList;
        }
        catch (OWLReasonerException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Reasoner error", e);
		}
		catch (ConversionException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Protege to OWLAPI conversion error", e);
		}
		catch (OWLException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("OWLAPI error", e);
		}
		finally {
			if (mTaskListener != null) aTask.removeTaskListener(mTaskListener);
		}
    }

	public Collection<OWLClass> getEquivalentClasses(OWLClass theClass) throws DIGReasonerException {
        DefaultReasonerTask aTask = new DefaultReasonerTask(this, 1, "Get equivalent classes of: " + theClass);
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel.getProject());

        if (mTaskListener != null)
            aTask.addTaskListener(mTaskListener);

        try {
            aTask.setMessage("Updating Reasoner");

            updateReasoner(aReasoner);

            aTask.setMessage("Getting Equivalent Classes of " + theClass);

            Set<org.semanticweb.owl.model.OWLClass> aEquivs = aReasoner.getEquivalentClasses(mConverter.convertClass(theClass)) ;

            Set<OWLClass> aList = new HashSet<OWLClass>();

            for (org.semanticweb.owl.model.OWLClass aClass : aEquivs) {
                aList.add(mConverter.toProtegeClass(aClass, getKnowledgeBase()));
            }

            aTask.incrementProgress();

            aTask.taskCompleted();

            return aList;
        }
        catch (OWLReasonerException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Reasoner error", e);
		}
		catch (ConversionException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Protege to OWLAPI conversion error", e);
		}
		catch (OWLException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("OWLAPI error", e);
		}
		finally {
			if (mTaskListener != null) aTask.removeTaskListener(mTaskListener);
		}
    }

	public Collection<OWLIndividual> getIndividualsBelongingToClass(OWLClass theClass) throws DIGReasonerException {
        DefaultReasonerTask aTask = new DefaultReasonerTask(this, 1, "Get individuals belonging to class: " + theClass);
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel.getProject());

        if (mTaskListener != null)
            aTask.addTaskListener(mTaskListener);

        try {
            aTask.setMessage("Updating Reasoner");

            updateReasoner(aReasoner);

            aTask.setMessage("Getting Individuals belonging to class" + theClass);

            Set<org.semanticweb.owl.model.OWLIndividual> aIndList = aReasoner.getIndividuals(mConverter.convertClass(theClass), false);

            Set<OWLIndividual> aList = new HashSet<OWLIndividual>();

            for (org.semanticweb.owl.model.OWLIndividual aInd : aIndList) {
                aList.add(mConverter.toProtegeIndividual(aInd, getKnowledgeBase()));
            }

            aTask.incrementProgress();

            aTask.taskCompleted();

            return aList;
        }
		catch (OWLReasonerException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Reasoner error", e);
		}
		catch (ConversionException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Protege to OWLAPI conversion error", e);
		}
		catch (OWLException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("OWLAPI error", e);
		}
        finally {
            if (mTaskListener != null)
                aTask.removeTaskListener(mTaskListener);
        }
    }

	public Collection<OWLClass> getIndividualTypes(OWLIndividual theIndividual) throws DIGReasonerException {
        DefaultReasonerTask aTask = new DefaultReasonerTask(this, 1, "Get individual types of " + theIndividual);
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel.getProject());

        if (mTaskListener != null)
            aTask.addTaskListener(mTaskListener);

        try {
            aTask.setMessage("Updating Reasoner");

            updateReasoner(aReasoner);

            aTask.setMessage("Getting individual types of " + theIndividual);

            Set<Set<org.semanticweb.owl.model.OWLClass>> aTypes = aReasoner.getTypes(mConverter.convertIndividual(theIndividual), false);

            Set<OWLClass> aList = new HashSet<OWLClass>();

            for (Set<org.semanticweb.owl.model.OWLClass> aSet : aTypes) {
                for (org.semanticweb.owl.model.OWLClass aClass : aSet) {
                    aList.add(mConverter.toProtegeClass(aClass, getKnowledgeBase()));
                }
            }

            aTask.incrementProgress();

            aTask.taskCompleted();

            return aList;
        }

		catch (OWLReasonerException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Reasoner error", e);
		}
		catch (ConversionException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Protege to OWLAPI conversion error", e);
		}
		catch (OWLException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("OWLAPI error", e);
		}
        finally {
            if (mTaskListener != null)
                aTask.removeTaskListener(mTaskListener);
        }
    }

	public OWLModel getKnowledgeBase() {
        return mModel;
    }

	public static String getReasonerName() {
		return "Clark & Parsia Custom Protege 3.x Reasoner";
	}
	
	public String getReasonerKnowledgeBaseURI() {
        return mModel.getDefaultOWLOntology().getURI();
    }

	public Collection<OWLClass> getSubclasses(OWLClass theClass) throws DIGReasonerException {
        DefaultReasonerTask aTask = new DefaultReasonerTask(this, 1, "Get subclasses of " + theClass);
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel.getProject());

        if (mTaskListener != null)
            aTask.addTaskListener(mTaskListener);

        try {
            aTask.setMessage("Updating Reasoner");

            updateReasoner(aReasoner);

            aTask.setMessage("Getting subclasses of " + theClass);

            Set<Set<org.semanticweb.owl.model.OWLClass>> aTypes = aReasoner.getSubClasses(mConverter.convertClass(theClass));

            Set<OWLClass> aList = new HashSet<OWLClass>();

            for (Set<org.semanticweb.owl.model.OWLClass> aSet : aTypes) {
                for (org.semanticweb.owl.model.OWLClass aClass : aSet) {
                    aList.add(mConverter.toProtegeClass(aClass, getKnowledgeBase()));
                }
            }

            aTask.incrementProgress();

            aTask.taskCompleted();

            return aList;
        }
        catch (OWLReasonerException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Reasoner error", e);
		}
		catch (ConversionException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Protege to OWLAPI conversion error", e);
		}
		catch (OWLException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("OWLAPI error", e);
		}
        finally {
            if (mTaskListener != null)
                aTask.removeTaskListener(mTaskListener);
        }
    }

	public int getSubsumptionRelationship(OWLClass theClass1, OWLClass theClass2, ReasonerTaskListener theTaskListener) throws DIGReasonerException {
        DefaultReasonerTask aTask = new DefaultReasonerTask(this, 1, "Determining subsumption relationship between " + theClass1 + " and " + theClass2);
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel.getProject());

        if (theTaskListener != null)
            aTask.addTaskListener(theTaskListener);

        try {
            aTask.setMessage("Updating Reasoner");

            updateReasoner(aReasoner);

            aTask.setMessage("Getting subsumption relationship between " + theClass1 + " and " + theClass2);

            int aReturn;

            if (aReasoner.isEquivalentClass(mConverter.convertClass(theClass1), mConverter.convertClass(theClass2))) {
                aReturn = ProtegeOWLReasoner.CLS1_EQUIVALENT_TO_CLS2;
            }
            else if (aReasoner.isSubClassOf(mConverter.convertClass(theClass1), mConverter.convertClass(theClass2))) {
                aReturn = ProtegeOWLReasoner.CLS1_SUBSUMED_BY_CLS2;
            }
            else if (aReasoner.isSubClassOf(mConverter.convertClass(theClass2), mConverter.convertClass(theClass1))) {
                aReturn = ProtegeOWLReasoner.CLS1_SUBSUMES_CLS2;
            }
            else aReturn = ProtegeOWLReasoner.NO_SUBSUMPTION_RELATIONSHIP;

            aTask.incrementProgress();

            aTask.taskCompleted();

            return aReturn;
        }
        catch (OWLReasonerException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Reasoner error", e);
		}
		catch (ConversionException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Protege to OWLAPI conversion error", e);
		}
		catch (OWLException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("OWLAPI error", e);
		}
		finally {
			if (theTaskListener != null) aTask.removeTaskListener(theTaskListener);
		}
    }

	public Collection<OWLClass> getSuperclasses(OWLClass theClass) throws DIGReasonerException {
        DefaultReasonerTask aTask = new DefaultReasonerTask(this, 1, "Get superclasses of " + theClass);
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel.getProject());

        if (mTaskListener != null)
            aTask.addTaskListener(mTaskListener);

        try {
            aTask.setMessage("Updating Reasoner");

            updateReasoner(aReasoner);

            aTask.setMessage("Getting super classes of " + theClass);

            Set<Set<org.semanticweb.owl.model.OWLClass>> aTypes = aReasoner.getSuperClasses(mConverter.convertClass(theClass)) ;

            Set<OWLClass> aList = new HashSet<OWLClass>();

            for (Set<org.semanticweb.owl.model.OWLClass> aSet : aTypes) {
                for (org.semanticweb.owl.model.OWLClass aClass : aSet) {
                    aList.add(mConverter.toProtegeClass(aClass, getKnowledgeBase()));
                }
            }

            aTask.incrementProgress();

            aTask.taskCompleted();

            return aList;
        }
        catch (OWLReasonerException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Reasoner error", e);
		}
		catch (ConversionException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Protege to OWLAPI conversion error", e);
		}
		catch (OWLException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Protege to OWLAPI conversion error", e);
		}
		finally {
			if (mTaskListener != null) aTask.removeTaskListener(mTaskListener);
		}
    }

	public Collection<OWLClass> getSuperclassesOfIntersection(OWLClass[] theClasses) throws DIGReasonerException {
        DefaultReasonerTask aTask = new DefaultReasonerTask(this, 1, "Get superclasses of intersection");
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel.getProject());

        if (mTaskListener != null)
            aTask.addTaskListener(mTaskListener);

        try {
            aTask.setMessage("Updating Reasoner");

            updateReasoner(aReasoner);

            aTask.setMessage("Getting super classes of an intersection");

            Set<OWLDescription> aClassSet = new HashSet<OWLDescription>();
            for (OWLClass aClass : theClasses)
                aClassSet.add(mConverter.convertClass(aClass));

            Set<Set<org.semanticweb.owl.model.OWLClass>> aSupers = aReasoner.getSuperClasses(
                    CustomReasonerProjectPlugin.getOWLDataFactory().getOWLObjectIntersectionOf(aClassSet));

            Set<OWLClass> aList = new HashSet<OWLClass>();

            for (Set<org.semanticweb.owl.model.OWLClass> aSet : aSupers) {
                for (org.semanticweb.owl.model.OWLClass aClass : aSet) {
                    aList.add(mConverter.toProtegeClass(aClass, getKnowledgeBase()));
                }
            }

            aTask.incrementProgress();

            aTask.taskCompleted();

            return aList;
        }
        catch (OWLReasonerException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Reasoner error", e);
		}
		catch (ConversionException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Protege to OWLAPI conversion error", e);
		}
		catch (OWLException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Protege to OWLAPI conversion error", e);
		}
		finally {
			if (mTaskListener != null) aTask.removeTaskListener(mTaskListener);
		}
    }

	public boolean isAutoSynchronizationEnabled() {
		return mAutoSync;
	}

	public boolean isConnected() {
		return true;
	}

	public boolean isDisjointTo(OWLClass theClass1, OWLClass theClass2) throws DIGReasonerException {
        DefaultReasonerTask aTask = new DefaultReasonerTask(this, 1, "Checking disjoint " + theClass1 + " and " + theClass2);
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel.getProject());

        if (mTaskListener != null)
            aTask.addTaskListener(mTaskListener);

        try {
            aTask.setMessage("Updating Reasoner");

            updateReasoner(aReasoner);

            boolean aReturn = aReasoner.isSubClassOf(mConverter.convertClass(theClass1),
                                                     CustomReasonerProjectPlugin.getOWLDataFactory().getOWLObjectComplementOf(
                                                             mConverter.convertClass(theClass2)));

            aTask.incrementProgress();

            aTask.taskCompleted();

            return aReturn;
        }
        catch (OWLReasonerException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Reasoner error", e);
		}
		catch (ConversionException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Protege to OWLAPI conversion error", e);
		}
		catch (OWLException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Protege to OWLAPI conversion error", e);
		}
		finally {
			if (mTaskListener != null) aTask.removeTaskListener(mTaskListener);
		}
    }

	public boolean isIntersectionSatisfiable(OWLClass[] theClasses) throws DIGReasonerException {
        DefaultReasonerTask aTask = new DefaultReasonerTask(this, 1, "Check intersection satisfiable");
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel.getProject());

        if (mTaskListener != null)
            aTask.addTaskListener(mTaskListener);

        try {
            aTask.setMessage("Updating Reasoner");

            updateReasoner(aReasoner);

            Set<OWLDescription> aClassSet = new HashSet<OWLDescription>();
            for (OWLClass aClass : theClasses)
                aClassSet.add(mConverter.convertClass(aClass));

            boolean aReturn = aReasoner.isSatisfiable(CustomReasonerProjectPlugin.getOWLDataFactory().getOWLObjectIntersectionOf(aClassSet));

            aTask.incrementProgress();

            aTask.taskCompleted();

            return aReturn;
        }
        catch (OWLReasonerException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Reasoner error", e);
		}
		catch (ConversionException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Protege to OWLAPI conversion error", e);
		}
		catch (OWLException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("OWLAPI error", e);
		}
		finally {
			if (mTaskListener != null) aTask.removeTaskListener(mTaskListener);
		}
    }

	public boolean isSatisfiable(OWLClass theClass) throws DIGReasonerException {
        DefaultReasonerTask aTask = new DefaultReasonerTask(this, 1, "Checking satisfiability of " + theClass);
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel.getProject());

        if (mTaskListener != null)
            aTask.addTaskListener(mTaskListener);

        try {
            aTask.setMessage("Updating Reasoner");

            updateReasoner(aReasoner);

            aTask.setMessage("Starting satisfiability check");

            boolean aReturn = aReasoner.isSatisfiable( mConverter.convertClass(theClass) );

            aTask.incrementProgress();

            aTask.taskCompleted();

            return aReturn;
        }
        catch (OWLReasonerException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Reasoner error", e);
		}
		catch (ConversionException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Protege to OWLAPI conversion error", e);
		}
		catch (OWLException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("OWLAPI error", e);
		}
        finally {
            if (mTaskListener != null)
                aTask.removeTaskListener(mTaskListener);
        }
    }

	public boolean isSubsumedBy(OWLClass theClass1, OWLClass theClass2) throws DIGReasonerException {
        DefaultReasonerTask aTask = new DefaultReasonerTask(this, 1, null);
        final DigReasoner aReasoner = CustomReasonerProjectPlugin.getDigReasoner(mModel.getProject());

        aTask.setMessage("Checking subsumption relationship between " + theClass1 + " and " + theClass2);

        if (mTaskListener != null)
            aTask.addTaskListener(mTaskListener);

        try {
            aTask.setMessage("Updating Reasoner");

            updateReasoner(aReasoner);

            boolean aReturn = aReasoner.isSubClassOf(  mConverter.convertClass(theClass1), mConverter.convertClass(theClass2) );

            aTask.incrementProgress();

            aTask.taskCompleted();

            return aReturn;
        }
        catch (OWLReasonerException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Reasoner error", e);
		}
		catch (ConversionException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("Protege to OWLAPI conversion error", e);
		}
		catch (OWLException e) {
			aTask.taskFailed();
			throw new DIGReasonerException("OWLAPI error", e);
		}
		finally {
			if (mTaskListener != null)
                aTask.removeTaskListener(mTaskListener);
		}
    }

	public void setAutoSynchronizationEnabled(boolean theAutoSync) {
        mAutoSync = theAutoSync;
    }

    private void resetHierarchy(DefaultReasonerTask theTask) {
        LOGGER.fine("resetHierarchy");

        theTask.setDescription("Resetting inferred hierarchy");
        theTask.setMessage("Clearing...");

        ReasonerLogRecord aParentRecord = ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Resetting inferred hierarchy", theTask.getParentRecord());
        ReasonerLogger.getInstance().postLogRecord(aParentRecord);

        theTask.setProgressIndeterminate(true);
        OWLModel kb = getKnowledgeBase();

        boolean eventsEnabled = kb.setGenerateEventsEnabled(false);
        try {
            long s = System.currentTimeMillis();

            kb.beginTransaction("Reset inferred hierarchy");

            OWLUtil.resetComputedSuperclasses(kb);

            theTask.setDescription("Commiting transaction");

            kb.commitTransaction();

            long e = System.currentTimeMillis();

            ReasonerLogger.getInstance().postLogRecord(
                    ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Reset hierarchy in " + (e-s) + "ms", theTask.getParentRecord()));
        }
        catch (Exception ex) {
            kb.rollbackTransaction();
            LOGGER.warning("Exception in transaction, rolling back.  Exception: " + ex.getMessage());
            throw new RuntimeException(ex);
        }

        kb.setGenerateEventsEnabled(eventsEnabled);

        theTask.setProgressIndeterminate(false);
    }

    private void updateInconsistentClasses(DefaultReasonerTask theTask, DigReasoner theReasoner) throws OWLReasonerException {
        LOGGER.fine("updateInconsistentClasses");

        theTask.setDescription("Computing inconsistent concepts");

        ReasonerLogRecord aParentRecord = ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Inconsistent concepts", theTask.getParentRecord());
        ReasonerLogger.getInstance().postLogRecord(aParentRecord);

        OWLModel kb = getKnowledgeBase();

        boolean eventsEnabled = kb.setGenerateEventsEnabled(false);

        long s = System.currentTimeMillis();

        Set<org.semanticweb.owl.model.OWLClass> aInconsistents = null;
        
        try {
            kb.beginTransaction("Compute and mark inconsistent classes");

            Iterator aClassesIter = ReasonerUtil.getInstance().getNamedClses(kb).iterator();

            theTask.setMessage("Querying reasoner for inconsistent concepts");

            aInconsistents = theReasoner.getInconsistentClasses();

            while (aClassesIter.hasNext()) {

                OWLNamedClass curNamedCls = (OWLNamedClass) aClassesIter.next();

                if (!aInconsistents.contains(mConverter.convertClass(curNamedCls))) {
                    curNamedCls.setClassificationStatus(OWLNames.CLASSIFICATION_STATUS_CONSISTENT_AND_UNCHANGED);
                    curNamedCls.removeInferredSuperclass(curNamedCls.getOWLModel().getOWLNamedClass(OWLNames.Cls.NOTHING));
                }
                else {
                    ReasonerLogger.getInstance().postLogRecord(ReasonerLogRecordFactory.getInstance().createConceptConsistencyLogRecord(curNamedCls, false, aParentRecord));

                    curNamedCls.setClassificationStatus(OWLNames.CLASSIFICATION_STATUS_INCONSISTENT);
                    curNamedCls.addInferredSuperclass(curNamedCls.getOWLModel().getOWLNamedClass(OWLNames.Cls.NOTHING));
                }

                theTask.incrementProgress();
            }

            LOGGER.fine("Finished updating protege model");

            theTask.setDescription("Commiting transaction");

            kb.commitTransaction();
        }
        catch (OWLReasonerException ex) {
            kb.rollbackTransaction();
            throw ex;
        }
        catch (Exception ex) {
            kb.rollbackTransaction();

            LOGGER.warning("error while computing inconsistent classes: " + ex.getMessage());

            throw new RuntimeException(ex);
        }
        kb.setGenerateEventsEnabled(eventsEnabled);

        long e = System.currentTimeMillis();

        ReasonerLogger.getInstance().postLogRecord(ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Time to compute inconsistent classes " + (e-s) + "ms", aParentRecord));
        ReasonerLogger.getInstance().postLogRecord(ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Number of inconsistent classes: " + aInconsistents.size(), aParentRecord));
    }

    private void updateInferredHierarchy(DefaultReasonerTask theTask, DigReasoner theReasoner) throws OWLReasonerException {
        LOGGER.fine("updateInferredHierarchy");

        theTask.setDescription("Computing inferred hierarchy");

        ReasonerLogRecord aParentRecord = ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Compute inferred hierarchy", theTask.getParentRecord());
        ReasonerLogger.getInstance().postLogRecord(aParentRecord);

        OWLModel kb = getKnowledgeBase();

        long s = System.currentTimeMillis();

        boolean eventsEnabled = kb.setGenerateEventsEnabled(false);

        try {
            kb.beginTransaction("Compute and update inferred class hierarchy");

            theTask.setMessage("Querying reasoner and updating Protege");

            Collection aNamedClasses = ReasonerUtil.getInstance().getNamedClses(kb);
            for (Object aObj : aNamedClasses) {

                OWLNamedClass aClass = (OWLNamedClass) aObj;

                if (aClass.isConsistent()) {

                    Set<Set<org.semanticweb.owl.model.OWLClass>> aSupers = theReasoner.getSuperClasses(mConverter.convertClass(aClass));
                    Set<OWLClass> aAllProtegeSupers = new HashSet<OWLClass>();

                    for (Set<org.semanticweb.owl.model.OWLClass> aSuperSet : aSupers) {
                        for (org.semanticweb.owl.model.OWLClass curSuperClass : aSuperSet) {

                            OWLClass aProtegeSuper = mConverter.toProtegeClass(curSuperClass, kb);

                            aAllProtegeSupers.add(aProtegeSuper);

                            // is this inferred or asserted?
                            //boolean aInferred = !aClass.getNamedSuperclasses().contains(aProtegeSuper);

                            // We don't want to assign invisible super classes!
                            if (aProtegeSuper.isVisible()) {
                                aClass.addInferredSuperclass(aProtegeSuper);
                            }
                        }
                    }

                    final Collection namedDirSuperCles = aClass.getNamedSuperclasses();

                    if (!new HashSet(namedDirSuperCles).equals(aAllProtegeSupers)) {
                        aClass.setClassificationStatus(OWLNames.CLASSIFICATION_STATUS_CONSISTENT_AND_CHANGED);
                    }
                    else {
                        aClass.setClassificationStatus(OWLNames.CLASSIFICATION_STATUS_CONSISTENT_AND_UNCHANGED);
                    }
                }
                else {
                    for (Object aSuperClass : aClass.getNamedSuperclasses()) {
                        aClass.addInferredSuperclass((RDFSClass) aSuperClass);
                    }
                }

                theTask.incrementProgress();
            }

            theTask.setDescription("Commiting transaction");

            kb.commitTransaction();
        }
        catch (OWLReasonerException ex) {
            kb.rollbackTransaction();
            throw ex;
        }
        catch (Exception ex) {
            ex.printStackTrace();
            kb.rollbackTransaction();

            LOGGER.warning("Error in update inferred hierarchy: " + ex.getMessage());

            throw new RuntimeException(ex);
        }
        
        kb.setGenerateEventsEnabled(eventsEnabled);

        long e = System.currentTimeMillis();

        ReasonerLogger.getInstance().postLogRecord(ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Time to compute inferred hierarchy " + (e-s) + "ms", aParentRecord));
    }

    private void updateEquivalentClasses(DefaultReasonerTask theTask, DigReasoner theReasoner) throws OWLReasonerException {
        LOGGER.fine("updateEquivalentClasses");

        theTask.setDescription("Updating Equivalent Classes");

        ReasonerLogRecord aParentRecord = ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Compute equivalent classes", theTask.getParentRecord());
        ReasonerLogger.getInstance().postLogRecord(aParentRecord);

        OWLModel kb = getKnowledgeBase();

        boolean eventsEnabled = kb.setGenerateEventsEnabled(false);

        long s = System.currentTimeMillis();

        try {
            kb.beginTransaction("Compute and update equivalent classes");

            Collection aNamedClasses = ReasonerUtil.getInstance().getNamedClses(kb);

            theTask.setMessage("Querying reasoner and updating Protege");

            for (Object aObj : aNamedClasses) {

                OWLNamedClass aClass = (OWLNamedClass) aObj;

                if (aClass.isConsistent()) {
                    Set<org.semanticweb.owl.model.OWLClass> aEquivSet = theReasoner.getEquivalentClasses(mConverter.convertClass(aClass));

                    for (org.semanticweb.owl.model.OWLClass aEquiv : aEquivSet) {
                        OWLNamedClass curSuperCls = mConverter.toProtegeClass(aEquiv, kb);

                        if (!curSuperCls.equals(aClass)) {
                            if (!aClass.getInferredSuperclasses().contains(curSuperCls)) {
                                aClass.addInferredSuperclass(curSuperCls);
                            }

                            if (!curSuperCls.getInferredSuperclasses().contains(aClass)) {
                                curSuperCls.addInferredSuperclass(aClass);
                            }
                        }
                    }
                }

                theTask.incrementProgress();
            }

            theTask.setDescription("Commiting transaction");

            kb.commitTransaction();
        }
        catch (OWLReasonerException ex) {
            kb.rollbackTransaction();
            throw ex;
        }
        catch (Exception ex) {
            kb.rollbackTransaction();

            LOGGER.warning("Error in update equivalent classes: " + ex.getMessage());

            throw new RuntimeException(ex);
        }

        kb.setGenerateEventsEnabled(eventsEnabled);

        long e = System.currentTimeMillis();

        ReasonerLogger.getInstance().postLogRecord(ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Time to compute equivalent concepts " + (e-s) + "ms", aParentRecord));
    }

    private void updateInferredTypes(DefaultReasonerTask theTask, DigReasoner theReasoner) throws OWLReasonerException {
        LOGGER.fine("updateInferredTypes");

        ReasonerLogRecord aParentRecord = ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Computing inferred types", theTask.getParentRecord());
        ReasonerLogger.getInstance().postLogRecord(aParentRecord);

        theTask.setDescription("Computing inferred types");

        OWLModel kb = getKnowledgeBase();

        long s = System.currentTimeMillis();

        // Disable the events as we may not be updating protege
        // from the event dispatch thread
        boolean eventsEnabled = kb.setGenerateEventsEnabled(false);

        try {
            kb.beginTransaction("Compute and update inferred types");

            Slot inferredTypesSlot = kb.getRDFProperty(ProtegeNames.Slot.INFERRED_TYPE);
            Slot classificationStatusSlot = kb.getProtegeClassificationStatusProperty();

            Iterator individualsIt = ReasonerUtil.getInstance().getIndividuals(kb).iterator();

            theTask.setMessage("Querying reasoner and updating Protege");
            while (individualsIt.hasNext()) {
                RDFIndividual curInd = (RDFIndividual) individualsIt.next();

                if (curInd != null) {
                    // Check the inferred types and asserted types
                    // if there is a mismatch between the two then
                    // mark the classification status of the individual
                    // as changed. (MH - 15/09/04)
                    Set<Set<org.semanticweb.owl.model.OWLClass>> owlInferredTypes = theReasoner.getTypes(mConverter.convertIndividual(curInd), false);
                    Set<OWLNamedClass> inferredTypes = new HashSet<OWLNamedClass>();

                    if (owlInferredTypes.size() == 0) {
                        inferredTypes.add(curInd.getOWLModel().getOWLThingClass());
                    }

                    for (Set<org.semanticweb.owl.model.OWLClass> aSet : owlInferredTypes) {
                        for (org.semanticweb.owl.model.OWLClass aClass : aSet) {
                            inferredTypes.add(mConverter.toProtegeClass(aClass, kb));
                        }
                    }

                    final Collection assertedTypes = curInd.getProtegeTypes();
                    KnowledgeBase k = kb;
                    k.setOwnSlotValues(curInd, inferredTypesSlot, inferredTypes);

                    if (!inferredTypes.equals(assertedTypes)) {
                        k.setOwnSlotValues(curInd, classificationStatusSlot, Collections.singleton(OWLNames.CLASSIFICATION_STATUS_CONSISTENT_AND_CHANGED));
                    }
                    else {
                        k.setOwnSlotValues(curInd, classificationStatusSlot, Collections.singleton(OWLNames.CLASSIFICATION_STATUS_CONSISTENT_AND_UNCHANGED));
                    }
                }

                theTask.incrementProgress();
            }

            theTask.setDescription("Commiting transaction");

            kb.commitTransaction();
        }
        catch (OWLReasonerException ex) {
            kb.rollbackTransaction();
            throw ex;
        }
        catch (Exception ex) {
            kb.rollbackTransaction();

            LOGGER.warning("Error while computing inferred types: " + ex.getMessage());

            throw new RuntimeException(ex);
        }

        kb.setGenerateEventsEnabled(eventsEnabled);

        long e = System.currentTimeMillis();

        ReasonerLogger.getInstance().postLogRecord(ReasonerLogRecordFactory.getInstance().createInformationMessageLogRecord("Time to compute update inferred hierarchy " + (e-s) + "ms", aParentRecord));
    }

	public ReasonerTaskListener getReasonerTaskListener() {
		return mTaskListener;
	}

	public void setReasonerTaskListener(ReasonerTaskListener theReasonerTaskListener) {
		mTaskListener = theReasonerTaskListener;
	}

    public void setOWLModel(OWLModel theModel) {
        mModel = theModel;
        mProtegeThing = mModel.getOWLThingClass();
        mProtegeNothing = mModel.getOWLNothing();
        mInfSubSlt = mModel.getProtegeInferredSubclassesProperty();
        mInfSupSlt = mModel.getProtegeInferredSuperclassesProperty();

        mAsyncUpdate = theModel.getProject().isMultiUserServer();

        if (mAsyncUpdate) {
            mExecutor = Executors.newSingleThreadExecutor();
            mPendingOps = new LinkedList<Future<? extends DigAsynchronousOperation>>();
        }
        else {
            mExecutor = null;
            mPendingOps = null;
        }

        if (theModel.getProject().isMultiUserClient() && SERVER_SIDE_CLASSIFY) {
            FrameStoreManager fsm = theModel.getFrameStoreManager();
            LocalClassificationFrameStore lcfs = fsm
                    .getFrameStoreFromClass(LocalClassificationFrameStore.class);
            if (lcfs != null) {
                fsm.removeFrameStore(lcfs);
                LOGGER
                        .log(Level.INFO,
                                "Removed local classification frame store (to enable server side classification).");
            }
        }

    }

    public void reset() {
        mModel = null;
        mProtegeThing = null;
        mProtegeNothing = null;
        mInfSubSlt = null;
        mInfSupSlt = null;
        mExecutor = null;
        mPendingOps = null;
        mStatusMap.clear();
    }

	public OWLModel getOWLModel() {
		return mModel;
	}

	public Collection<OWLProperty> getAncestorProperties(OWLProperty property)
			throws ProtegeReasonerException {
		throw new UnsupportedOperationException();
	}

	public Collection<OWLProperty> getDescendantProperties(OWLProperty property)
			throws ProtegeReasonerException {
		throw new UnsupportedOperationException();
	}

	public Collection<OWLClass> getIndividualDirectTypes(OWLIndividual individual)
			throws ProtegeReasonerException {
		throw new UnsupportedOperationException();
	}

	public Collection<OWLIndividual> getRelatedIndividuals(OWLIndividual subject,
			OWLObjectProperty objectProperty) throws ProtegeReasonerException {
		throw new UnsupportedOperationException();
	}

	public Collection getRelatedValues(OWLIndividual subject, OWLDatatypeProperty datatypeProperty)
			throws ProtegeReasonerException {
		throw new UnsupportedOperationException();
	}

	public Collection<OWLProperty> getSubProperties(OWLProperty property)
			throws ProtegeReasonerException {
		throw new UnsupportedOperationException();
	}

	public Collection<OWLProperty> getSuperProperties(OWLProperty property)
			throws ProtegeReasonerException {
		throw new UnsupportedOperationException();
	}

	public void initialize() {
		// Intentional no-op
	}

	public void rebind() {
		// Intentional no-op
	}

    class LRUMap<K, V> implements Map<K, V> {
        private LinkedHashMap<K, V> mMap = new LinkedHashMap<K, V>();
        private int mSize = 10;

        public LRUMap(int theSize) {
            mSize = theSize;
        }

        public int size() {
            return mMap.size();
        }

        public boolean isEmpty() {
            return mMap.isEmpty();
        }

        public boolean containsKey(Object o) {
            return mMap.containsKey(o);
        }

        public boolean containsValue(Object o) {
            return mMap.containsValue(o);
        }

        public V get(Object o) {
            V aV = mMap.get(o);

            if (aV != null) {
                // this basically puts it at the end of the iteration marking it as recently used since when its time
                // to remove the LRU element, its the first in the iteration that is remove, which is the entry with
                // the oldest "timestamp" on it.

                remove(o);
                put( (K) o, aV);
            }

            return aV;
        }

        public V put(K theK, V theV) {
            V aV = mMap.put(theK, theV);

            if (mMap.size() > mSize) {
                remove(mMap.keySet().iterator().next());
            }

            return aV;
        }

        public V remove(Object o) {
            return mMap.remove(o);
        }

        public void putAll(Map<? extends K, ? extends V> theMap) {
            for (Map.Entry<? extends K, ? extends V> aEntry : theMap.entrySet()) {
                put(aEntry.getKey(), aEntry.getValue());
            }
        }

        public void clear() {
            mMap.clear();
        }

        public Set<K> keySet() {
            return mMap.keySet();
        }

        public Collection<V> values() {
            return mMap.values();
        }

        public Set<Entry<K, V>> entrySet() {
            return mMap.entrySet();
        }
    }
}
